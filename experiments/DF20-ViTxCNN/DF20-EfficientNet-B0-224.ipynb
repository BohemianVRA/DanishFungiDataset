{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import timm\n",
    "import torch\n",
    "import random\n",
    "import sklearn.metrics\n",
    "\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from functools import partial\n",
    "from contextlib import contextmanager\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.optim import Adam, SGD, AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from albumentations import Compose, Normalize, Resize\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Mar 10 11:57:07 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.39       Driver Version: 460.39       CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce RTX 207...  Off  | 00000000:04:00.0 Off |                  N/A |\n",
      "| 20%   31C    P8     8W / 215W |     13MiB /  7982MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce RTX 3080    Off  | 00000000:09:00.0 Off |                  N/A |\n",
      "|100%   72C    P2   301W / 340W |   6946MiB / 10014MiB |     90%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  GeForce RTX 208...  Off  | 00000000:0A:00.0 Off |                  N/A |\n",
      "| 27%   38C    P8    21W / 250W |     10MiB /  7982MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "266344\n",
      "29594\n"
     ]
    }
   ],
   "source": [
    "train_metadata = pd.read_csv(\"/Datasets/DF20/metadata/DanishFungi2020_train_metadata_DEV.csv\")\n",
    "print(len(train_metadata))\n",
    "\n",
    "test_metadata = pd.read_csv(\"/Datasets/DF20/metadata/DanishFungi2020_test_metadata_DEV.csv\")\n",
    "print(len(test_metadata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gbifID</th>\n",
       "      <th>eventDate</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>countryCode</th>\n",
       "      <th>locality</th>\n",
       "      <th>identifiedBy</th>\n",
       "      <th>taxonID</th>\n",
       "      <th>scientificName</th>\n",
       "      <th>...</th>\n",
       "      <th>image_url</th>\n",
       "      <th>Substrate</th>\n",
       "      <th>rightsHolder</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>CoorUncert</th>\n",
       "      <th>Habitat</th>\n",
       "      <th>image_path</th>\n",
       "      <th>class_id</th>\n",
       "      <th>genus_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2238546328</td>\n",
       "      <td>2018-04-16T00:00:00</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>DK</td>\n",
       "      <td>Ulvedal Plantage</td>\n",
       "      <td>Ulfva Melchior Hvidegaard</td>\n",
       "      <td>30872.0</td>\n",
       "      <td>Ramalina farinacea (L.) Ach.</td>\n",
       "      <td>...</td>\n",
       "      <td>https://api.gbif.org/v1/image/unsafe/https://s...</td>\n",
       "      <td>bark of living trees</td>\n",
       "      <td>Ulfva Melchior Hvidegaard</td>\n",
       "      <td>56.299706</td>\n",
       "      <td>9.258110</td>\n",
       "      <td>50.0</td>\n",
       "      <td>Mixed woodland (with coniferous and deciduous ...</td>\n",
       "      <td>/Datasets/SvampeAtlas-14.12.2020/2238546328-30...</td>\n",
       "      <td>1273</td>\n",
       "      <td>453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2558871973</td>\n",
       "      <td>2020-01-03T00:00:00</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>DK</td>\n",
       "      <td>Slotshegn</td>\n",
       "      <td>Thomas Læssøe</td>\n",
       "      <td>15256.0</td>\n",
       "      <td>Hysterium acuminatum Fr.</td>\n",
       "      <td>...</td>\n",
       "      <td>https://api.gbif.org/v1/image/unsafe/https://s...</td>\n",
       "      <td>dead wood (including bark)</td>\n",
       "      <td>Ole Martin</td>\n",
       "      <td>55.861899</td>\n",
       "      <td>11.975973</td>\n",
       "      <td>50.0</td>\n",
       "      <td>Deciduous woodland</td>\n",
       "      <td>/Datasets/SvampeAtlas-14.12.2020/2558871973-53...</td>\n",
       "      <td>708</td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2238503501</td>\n",
       "      <td>2017-08-22T00:00:00</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>DK</td>\n",
       "      <td>Petersborg Strandenge</td>\n",
       "      <td>Per Taudal Poulsen</td>\n",
       "      <td>61200.0</td>\n",
       "      <td>Gliophorus perplexus (A.H.Sm. &amp; Hesler) Kovalenko</td>\n",
       "      <td>...</td>\n",
       "      <td>https://api.gbif.org/v1/image/unsafe/https://s...</td>\n",
       "      <td>soil</td>\n",
       "      <td>Per Taudal Poulsen</td>\n",
       "      <td>56.975158</td>\n",
       "      <td>9.285525</td>\n",
       "      <td>75.0</td>\n",
       "      <td>natural grassland</td>\n",
       "      <td>/Datasets/SvampeAtlas-14.12.2020/2238503501-24...</td>\n",
       "      <td>535</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2446759075</td>\n",
       "      <td>2019-10-26T00:00:00</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>DK</td>\n",
       "      <td>Klintebjerg</td>\n",
       "      <td>Susanne Rabenborg</td>\n",
       "      <td>30530.0</td>\n",
       "      <td>Lecidella scabra (Taylor) Hertel &amp; Leuckert</td>\n",
       "      <td>...</td>\n",
       "      <td>https://api.gbif.org/v1/image/unsafe/https://s...</td>\n",
       "      <td>stone</td>\n",
       "      <td>Susanne Rabenborg</td>\n",
       "      <td>55.960242</td>\n",
       "      <td>11.583103</td>\n",
       "      <td>15.0</td>\n",
       "      <td>gravel or clay pit</td>\n",
       "      <td>/Datasets/SvampeAtlas-14.12.2020/2446759075-19...</td>\n",
       "      <td>832</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2238472345</td>\n",
       "      <td>2016-08-21T00:00:00</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>DK</td>\n",
       "      <td>Blåbjerg</td>\n",
       "      <td>Tom Smidth</td>\n",
       "      <td>63728.0</td>\n",
       "      <td>Russula fragilis Fr., 1838</td>\n",
       "      <td>...</td>\n",
       "      <td>https://api.gbif.org/v1/image/unsafe/https://s...</td>\n",
       "      <td>soil</td>\n",
       "      <td>Tom Smidth</td>\n",
       "      <td>55.742985</td>\n",
       "      <td>8.250188</td>\n",
       "      <td>50.0</td>\n",
       "      <td>Mixed woodland (with coniferous and deciduous ...</td>\n",
       "      <td>/Datasets/SvampeAtlas-14.12.2020/2238472345-16...</td>\n",
       "      <td>1338</td>\n",
       "      <td>476</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       gbifID            eventDate    year  month   day countryCode  \\\n",
       "0  2238546328  2018-04-16T00:00:00  2018.0    4.0  16.0          DK   \n",
       "1  2558871973  2020-01-03T00:00:00  2020.0    1.0   3.0          DK   \n",
       "2  2238503501  2017-08-22T00:00:00  2017.0    8.0  22.0          DK   \n",
       "3  2446759075  2019-10-26T00:00:00  2019.0   10.0  26.0          DK   \n",
       "4  2238472345  2016-08-21T00:00:00  2016.0    8.0  21.0          DK   \n",
       "\n",
       "                locality               identifiedBy  taxonID  \\\n",
       "0       Ulvedal Plantage  Ulfva Melchior Hvidegaard  30872.0   \n",
       "1              Slotshegn              Thomas Læssøe  15256.0   \n",
       "2  Petersborg Strandenge         Per Taudal Poulsen  61200.0   \n",
       "3            Klintebjerg          Susanne Rabenborg  30530.0   \n",
       "4               Blåbjerg                 Tom Smidth  63728.0   \n",
       "\n",
       "                                      scientificName  ...  \\\n",
       "0                       Ramalina farinacea (L.) Ach.  ...   \n",
       "1                           Hysterium acuminatum Fr.  ...   \n",
       "2  Gliophorus perplexus (A.H.Sm. & Hesler) Kovalenko  ...   \n",
       "3        Lecidella scabra (Taylor) Hertel & Leuckert  ...   \n",
       "4                         Russula fragilis Fr., 1838  ...   \n",
       "\n",
       "                                           image_url  \\\n",
       "0  https://api.gbif.org/v1/image/unsafe/https://s...   \n",
       "1  https://api.gbif.org/v1/image/unsafe/https://s...   \n",
       "2  https://api.gbif.org/v1/image/unsafe/https://s...   \n",
       "3  https://api.gbif.org/v1/image/unsafe/https://s...   \n",
       "4  https://api.gbif.org/v1/image/unsafe/https://s...   \n",
       "\n",
       "                    Substrate               rightsHolder   Latitude  \\\n",
       "0        bark of living trees  Ulfva Melchior Hvidegaard  56.299706   \n",
       "1  dead wood (including bark)                 Ole Martin  55.861899   \n",
       "2                        soil         Per Taudal Poulsen  56.975158   \n",
       "3                       stone          Susanne Rabenborg  55.960242   \n",
       "4                        soil                 Tom Smidth  55.742985   \n",
       "\n",
       "   Longitude CoorUncert                                            Habitat  \\\n",
       "0   9.258110       50.0  Mixed woodland (with coniferous and deciduous ...   \n",
       "1  11.975973       50.0                                 Deciduous woodland   \n",
       "2   9.285525       75.0                                  natural grassland   \n",
       "3  11.583103       15.0                                 gravel or clay pit   \n",
       "4   8.250188       50.0  Mixed woodland (with coniferous and deciduous ...   \n",
       "\n",
       "                                          image_path class_id genus_id  \n",
       "0  /Datasets/SvampeAtlas-14.12.2020/2238546328-30...     1273      453  \n",
       "1  /Datasets/SvampeAtlas-14.12.2020/2558871973-53...      708      246  \n",
       "2  /Datasets/SvampeAtlas-14.12.2020/2238503501-24...      535      186  \n",
       "3  /Datasets/SvampeAtlas-14.12.2020/2446759075-19...      832      276  \n",
       "4  /Datasets/SvampeAtlas-14.12.2020/2238472345-16...     1338      476  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def timer(name):\n",
    "    t0 = time.time()\n",
    "    LOGGER.info(f'[{name}] start')\n",
    "    yield\n",
    "    LOGGER.info(f'[{name}] done in {time.time() - t0:.0f} s.')\n",
    "\n",
    "    \n",
    "def init_logger(log_file='train.log'):\n",
    "    from logging import getLogger, DEBUG, FileHandler,  Formatter,  StreamHandler\n",
    "    \n",
    "    log_format = '%(asctime)s %(levelname)s %(message)s'\n",
    "    \n",
    "    stream_handler = StreamHandler()\n",
    "    stream_handler.setLevel(DEBUG)\n",
    "    stream_handler.setFormatter(Formatter(log_format))\n",
    "    \n",
    "    file_handler = FileHandler(log_file)\n",
    "    file_handler.setFormatter(Formatter(log_format))\n",
    "    \n",
    "    logger = getLogger('Herbarium')\n",
    "    logger.setLevel(DEBUG)\n",
    "    logger.addHandler(stream_handler)\n",
    "    logger.addHandler(file_handler)\n",
    "    \n",
    "    return logger\n",
    "\n",
    "LOG_FILE = '../../logs/DF20/-EfficientNet-B0-224.log'\n",
    "LOGGER = init_logger(LOG_FILE)\n",
    "\n",
    "\n",
    "def seed_torch(seed=777):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "SEED = 777\n",
    "seed_torch(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path = self.df['image_path'].values[idx]\n",
    "        label = self.df['class_id'].values[idx]\n",
    "        image = cv2.imread(file_path)\n",
    "        \n",
    "        try:\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        except:\n",
    "            print(file_path)\n",
    "\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image)\n",
    "            image = augmented['image']\n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEIGHT = 224\n",
    "WIDTH = 224\n",
    "\n",
    "\n",
    "from albumentations import RandomCrop, HorizontalFlip, VerticalFlip, RandomBrightnessContrast, CenterCrop, PadIfNeeded, RandomResizedCrop\n",
    "\n",
    "def get_transforms(*, data):\n",
    "    assert data in ('train', 'valid')\n",
    "\n",
    "    if data == 'train':\n",
    "        return Compose([\n",
    "            RandomResizedCrop(WIDTH, HEIGHT, scale=(0.8, 1.0)),\n",
    "            HorizontalFlip(p=0.5),\n",
    "            VerticalFlip(p=0.5),\n",
    "            RandomBrightnessContrast(p=0.2),\n",
    "            Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225],\n",
    "            ),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "\n",
    "    elif data == 'valid':\n",
    "        return Compose([\n",
    "            Resize(WIDTH, HEIGHT),\n",
    "            Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225],\n",
    "            ),\n",
    "            ToTensorV2(),\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CLASSES = len(train_metadata['class_id'].unique())\n",
    "\n",
    "train_dataset = TrainDataset(train_metadata, transform=get_transforms(data='train'))\n",
    "valid_dataset = TrainDataset(test_metadata, transform=get_transforms(data='valid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust BATCH_SIZE and ACCUMULATION_STEPS to values that if multiplied results in 64 !!!!!1\n",
    "BATCH_SIZE = 32\n",
    "ACCUMULATION_STEPS = 2\n",
    "EPOCHS = 100\n",
    "WORKERS = 8\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=WORKERS)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n"
     ]
    }
   ],
   "source": [
    "from efficientnet_pytorch import EfficientNet\n",
    "model = EfficientNet.from_pretrained('efficientnet-b0')\n",
    "\n",
    "model._fc = nn.Linear(model._fc.in_features, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-10 11:57:51,871 INFO [Train model] start\n",
      "8324it [42:28,  3.27it/s]\n",
      "2021-03-10 12:45:10,237 DEBUG   Epoch 1 - avg_train_loss: 0.9758  avg_val_loss: 2.6483 F1: 0.215129  Accuracy: 0.413090 Recall@3: 0.600662 time: 2837s\n",
      "2021-03-10 12:45:10,238 DEBUG   Epoch 1 - Save Best Accuracy: 0.413090 Model\n",
      "2021-03-10 12:45:10,316 DEBUG   Epoch 1 - Save Best Loss: 2.6483 Model\n",
      "8324it [42:36,  3.26it/s]\n",
      "2021-03-10 13:32:24,438 DEBUG   Epoch 2 - avg_train_loss: 0.5952  avg_val_loss: 2.0367 F1: 0.352075  Accuracy: 0.522403 Recall@3: 0.709840 time: 2834s\n",
      "2021-03-10 13:32:24,439 DEBUG   Epoch 2 - Save Best Accuracy: 0.522403 Model\n",
      "2021-03-10 13:32:24,500 DEBUG   Epoch 2 - Save Best Loss: 2.0367 Model\n",
      "8324it [42:33,  3.26it/s]\n",
      "2021-03-10 14:19:38,109 DEBUG   Epoch 3 - avg_train_loss: 0.4927  avg_val_loss: 1.8585 F1: 0.410297  Accuracy: 0.558593 Recall@3: 0.744577 time: 2834s\n",
      "2021-03-10 14:19:38,110 DEBUG   Epoch 3 - Save Best Accuracy: 0.558593 Model\n",
      "2021-03-10 14:19:38,169 DEBUG   Epoch 3 - Save Best Loss: 1.8585 Model\n",
      "4656it [23:43,  2.95it/s]"
     ]
    }
   ],
   "source": [
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from sklearn.metrics import f1_score, accuracy_score, top_k_accuracy_score\n",
    "import tqdm\n",
    "\n",
    "\n",
    "with timer('Train model'):\n",
    "    accumulation_steps = ACCUMULATION_STEPS\n",
    "    n_epochs = EPOCHS\n",
    "    lr = 0.01\n",
    "    \n",
    "    model.to(device)\n",
    "    \n",
    "    optimizer = SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, 'min', factor=0.9, patience=1, verbose=True, eps=1e-6)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    best_score = 0.\n",
    "    best_loss = np.inf\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        \n",
    "        start_time = time.time()\n",
    "\n",
    "        model.train()\n",
    "        avg_loss = 0.\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        for i, (images, labels) in tqdm.tqdm(enumerate(train_loader)):\n",
    "\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            y_preds = model(images)\n",
    "            loss = criterion(y_preds, labels)\n",
    "\n",
    "            # Scale the loss to the mean of the accumulated batch size\n",
    "            loss = loss / accumulation_steps\n",
    "            loss.backward()\n",
    "            if (i - 1) % accumulation_steps == 0:\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                avg_loss += loss.item() / len(train_loader)\n",
    "\n",
    "        model.eval()\n",
    "        avg_val_loss = 0.\n",
    "        preds = np.zeros((len(valid_dataset)))\n",
    "        preds_raw = []\n",
    "\n",
    "        for i, (images, labels) in enumerate(valid_loader):\n",
    "            \n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                y_preds = model(images)\n",
    "            \n",
    "            preds[i * BATCH_SIZE: (i+1) * BATCH_SIZE] = y_preds.argmax(1).to('cpu').numpy()\n",
    "            preds_raw.extend(y_preds.to('cpu').numpy())\n",
    "\n",
    "            loss = criterion(y_preds, labels)\n",
    "            avg_val_loss += loss.item() / len(valid_loader)\n",
    "        \n",
    "        scheduler.step(avg_val_loss)\n",
    "            \n",
    "        score = f1_score(test_metadata['class_id'], preds, average='macro')\n",
    "        accuracy = accuracy_score(test_metadata['class_id'], preds)\n",
    "        recall_3 = top_k_accuracy_score(test_metadata['class_id'], preds_raw, k=3)\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "\n",
    "        LOGGER.debug(f'  Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f} F1: {score:.6f}  Accuracy: {accuracy:.6f} Recall@3: {recall_3:.6f} time: {elapsed:.0f}s')\n",
    "\n",
    "        if accuracy>best_score:\n",
    "            best_score = accuracy\n",
    "            LOGGER.debug(f'  Epoch {epoch+1} - Save Best Accuracy: {best_score:.6f} Model')\n",
    "            torch.save(model.state_dict(), f'DF20-EfficientNet-B0-224_best_accuracy.pth')\n",
    "\n",
    "        if avg_val_loss<best_loss:\n",
    "            best_loss = avg_val_loss\n",
    "            LOGGER.debug(f'  Epoch {epoch+1} - Save Best Loss: {best_loss:.4f} Model')\n",
    "            torch.save(model.state_dict(), f'DF20-EfficientNet-B0-224_best_loss.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f'DF20-EfficientNet-B0-224-100E.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
