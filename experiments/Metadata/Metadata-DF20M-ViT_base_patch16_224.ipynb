{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "import json\n",
    "import tqdm\n",
    "import time\n",
    "import timm\n",
    "import torch\n",
    "import random\n",
    "import sklearn.metrics\n",
    "\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from functools import partial\n",
    "from contextlib import contextmanager\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.optim import Adam, SGD\n",
    "from scipy.special import softmax\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from albumentations import Compose, Normalize, Resize\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from sklearn.metrics import f1_score, accuracy_score, top_k_accuracy_score\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Parsing Metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading metadata files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metadata_genera = pd.read_csv(\"/Datasets/SvampeAtlas-14.12.2020/metadata/DanishFungi2020-Mini_train_metadata_DEV.csv\")\n",
    "test_metadata_genera = pd.read_csv(\"/Datasets/SvampeAtlas-14.12.2020/metadata/DanishFungi2020-Mini_test_metadata_DEV.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32753 3640\n"
     ]
    }
   ],
   "source": [
    "print(len(train_metadata_genera), len(test_metadata_genera))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "295938"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata = pd.concat([train_metadata, test_metadata])\n",
    "len(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metadata_genera.Habitat = test_metadata_genera.Habitat.replace(np.nan, 'unknown', regex=True)\n",
    "test_metadata_genera.Substrate = test_metadata_genera.Substrate.replace(np.nan, 'unknown', regex=True)\n",
    "# test_metadata.month = test_metadata.month.replace(np.nan, 'unknown', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metadata_genera.Habitat = train_metadata_genera.Habitat.replace(np.nan, 'unknown', regex=True)\n",
    "train_metadata_genera.Substrate = train_metadata_genera.Substrate.replace(np.nan, 'unknown', regex=True)\n",
    "# metadata.month = metadata.month.replace(np.nan, 0, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['bark of living trees', 'dead wood (including bark)', 'soil',\n",
       "       'stone', 'leaf or needle litter', 'wood', 'living leaves', 'bark',\n",
       "       'siliceous stone', 'cones', 'peat mosses',\n",
       "       'stems of herbs, grass etc', 'building stone (e.g. bricks)',\n",
       "       'dead stems of herbs, grass etc', 'wood chips or mulch', 'unknown',\n",
       "       'wood and roots of living trees',\n",
       "       'living stems of herbs, grass etc', 'faeces', 'mosses', 'fungi',\n",
       "       'insects', 'fruits', 'fire spot', 'catkins', 'lichens',\n",
       "       'other substrate', 'calcareous stone', 'living flowers',\n",
       "       'remains of vertebrates (e.g. feathers and fur)', 'liverworts',\n",
       "       'mycetozoans'], dtype=object)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata.Substrate.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_to_genus = np.zeros(len(train_metadata_genera['class_id'].unique()))\n",
    "for species in train_metadata_genera['class_id'].unique():\n",
    "    class_to_genus[species] = train_metadata_genera[train_metadata_genera['class_id'] == species]['genus_id'].unique()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Species distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_priors = np.zeros(len(train_metadata_genera['class_id'].unique()))\n",
    "for species in train_metadata_genera['class_id'].unique():\n",
    "    class_priors[species] = len(train_metadata_genera[train_metadata_genera['class_id'] == species])\n",
    "\n",
    "class_priors = class_priors/sum(class_priors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting species-month distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32753/32753 [00:04<00:00, 7303.11it/s]\n"
     ]
    }
   ],
   "source": [
    "month_distributions = {}\n",
    "\n",
    "for _, observation in tqdm.tqdm(train_metadata_genera.iterrows(), total=len(train_metadata_genera)):\n",
    "    month = str(observation.month)\n",
    "    class_id = observation.class_id\n",
    "    if month not in month_distributions:        \n",
    "        month_distributions[month] = np.zeros(len(train_metadata_genera['class_id'].unique()))\n",
    "    else:\n",
    "        month_distributions[month][class_id] += 1\n",
    "\n",
    "for key, value in month_distributions.items():\n",
    "    month_distributions[key] = value / sum(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting species-habitat distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32753/32753 [00:03<00:00, 8288.71it/s]\n",
      "<ipython-input-44-1980391a20f2>:12: RuntimeWarning: invalid value encountered in true_divide\n",
      "  habitat_distributions[key] = value / sum(value)\n"
     ]
    }
   ],
   "source": [
    "habitat_distributions = {}\n",
    "\n",
    "for _, observation in tqdm.tqdm(train_metadata_genera.iterrows(), total=len(train_metadata_genera)):\n",
    "    habitat = observation.Habitat\n",
    "    class_id = observation.class_id\n",
    "    if habitat not in habitat_distributions:        \n",
    "        habitat_distributions[habitat] = np.zeros(len(train_metadata_genera['class_id'].unique()))\n",
    "    else:\n",
    "        habitat_distributions[habitat][class_id] += 1\n",
    "\n",
    "for key, value in habitat_distributions.items():\n",
    "    habitat_distributions[key] = value / sum(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting species-substrate distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32753/32753 [00:04<00:00, 8167.25it/s]\n",
      "<ipython-input-45-eb67722e2d43>:12: RuntimeWarning: invalid value encountered in true_divide\n",
      "  substrate_distributions[key] = value / sum(value)\n"
     ]
    }
   ],
   "source": [
    "substrate_distributions = {}\n",
    "\n",
    "for _, observation in tqdm.tqdm(train_metadata_genera.iterrows(), total=len(train_metadata_genera)):\n",
    "    substrate = observation.Substrate\n",
    "    class_id = observation.class_id\n",
    "    if substrate not in substrate_distributions:        \n",
    "        substrate_distributions[substrate] = np.zeros(len(train_metadata_genera['class_id'].unique()))\n",
    "    else:\n",
    "        substrate_distributions[substrate][class_id] += 1\n",
    "\n",
    "for key, value in substrate_distributions.items():\n",
    "    substrate_distributions[key] = value / sum(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting with trained network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_torch(seed=777):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "SEED = 777\n",
    "seed_torch(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        file_path = self.df['image_path'].values[idx]\n",
    "        label = self.df['class_id'].values[idx]\n",
    "        month = self.df['month'].values[idx]\n",
    "        sub = self.df['Substrate'].values[idx]\n",
    "        hab = self.df['Habitat'].values[idx]\n",
    "        \n",
    "        image = cv2.imread(file_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image)\n",
    "            image = augmented['image']\n",
    "        return image, label, file_path, month, hab, sub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "WIDTH, HEIGHT = 224, 224\n",
    "\n",
    "def get_transforms():\n",
    "\n",
    "    return Compose([Resize(WIDTH, HEIGHT),\n",
    "                    Normalize(mean = model_mean, std = model_std),\n",
    "                    ToTensorV2()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getModel(architecture_name, target_size, pretrained = False):\n",
    "    net = timm.create_model(architecture_name, pretrained=pretrained)\n",
    "    net_cfg = net.default_cfg\n",
    "    last_layer = net_cfg['classifier']\n",
    "    num_ftrs = getattr(net, last_layer).in_features\n",
    "    setattr(net, last_layer, nn.Linear(num_ftrs, target_size))\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 182\n",
    "\n",
    "\n",
    "MODEL_NAME = 'vit_base_patch16_224'\n",
    "#MODEL_NAME = 'vit_large_patch16_384'\n",
    "model = getModel(MODEL_NAME, NUM_CLASSES, pretrained=True)\n",
    "model_mean = list(model.default_cfg['mean'])\n",
    "model_std = list(model.default_cfg['std'])\n",
    "#model = nn.DataParallel(model)\n",
    "\n",
    "#READ STATE DICT!!!\n",
    "model.load_state_dict(torch.load('../../checkpoints/DF20M-ViT_base_patch16_224-GENERA-100E.pth'))\n",
    "\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_dataset_genera = TestDataset(test_metadata_genera, test_metadata_genera['class_id'], transform=get_transforms())\n",
    "test_dataset = TestDataset(test_metadata_genera, transform=get_transforms())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "#test_loader_genera = DataLoader(test_dataset_genera, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 228/228 [01:36<00:00,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vanilla: 0.586413701939184 0.6925824175824176 0.8653846153846154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "avg_val_loss = 0.\n",
    "preds = np.zeros((len(test_metadata_genera)))\n",
    "GT_lbls = []\n",
    "image_paths = []\n",
    "preds_raw = []\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "months = []\n",
    "subs = []\n",
    "habitats = []\n",
    "\n",
    "for i, (images, labels, paths, M, H, S) in enumerate(tqdm.tqdm(test_loader, total=len(test_loader))):\n",
    "\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        y_preds = model(images)\n",
    "    preds[i * batch_size: (i+1) * batch_size] = y_preds.argmax(1).to('cpu').numpy()\n",
    "    GT_lbls.extend(labels.to('cpu').numpy())\n",
    "    preds_raw.extend(y_preds.to('cpu').numpy())\n",
    "    image_paths.extend(paths)\n",
    "    months.extend(M)\n",
    "    subs.extend(S)\n",
    "    habitats.extend(H)\n",
    "\n",
    "vanilla_f1 = f1_score(test_metadata_genera['class_id'], preds, average='macro')\n",
    "vanilla_accuracy = accuracy_score(test_metadata_genera['class_id'], preds)\n",
    "vanilla_recall_3 = top_k_accuracy_score(test_metadata_genera['class_id'], preds_raw, k=3)\n",
    "\n",
    "print('Vanilla:', vanilla_f1, vanilla_accuracy, vanilla_recall_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighting by Habitat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3640/3640 [00:00<00:00, 6617.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Habitat: 0.6152773343556828 0.7096153846153846 0.8763736263736264\n",
      "Habitat dif: 0.028863632416498808 0.017032967032967083 0.01098901098901095\n"
     ]
    }
   ],
   "source": [
    "wrong_predictions_H = []\n",
    "weighted_predictions_H = []\n",
    "weighted_predictions_raw_H = []\n",
    "prior_ratio_H = []\n",
    "\n",
    "for lbl, preds, hab in tqdm.tqdm(zip(GT_lbls, preds_raw, habitats), total=len(GT_lbls)):\n",
    "    \n",
    "    habitat_dist = habitat_distributions[hab]\n",
    "    preds = softmax(preds)\n",
    "    \n",
    "    p_habitat = (preds * habitat_dist) / sum(preds * habitat_dist)\n",
    "    prior_ratio = p_habitat / class_priors\n",
    "    max_index = np.argmax(prior_ratio * preds)        \n",
    "    \n",
    "    prior_ratio_H.append(prior_ratio)\n",
    "    weighted_predictions_raw_H.append(prior_ratio * preds)\n",
    "    weighted_predictions_H.append(max_index)\n",
    "    \n",
    "    if lbl != max_index:\n",
    "        wrong_predictions_H.append([lbl, hab])\n",
    "\n",
    "f1 = f1_score(test_metadata_genera['class_id'], weighted_predictions_H, average='macro')\n",
    "accuracy = accuracy_score(test_metadata_genera['class_id'], weighted_predictions_H)\n",
    "recall_3 = top_k_accuracy_score(test_metadata_genera['class_id'], weighted_predictions_raw_H, k=3)\n",
    "print('Habitat:', f1, accuracy, recall_3)\n",
    "print('Habitat dif:', f1-vanilla_f1, accuracy-vanilla_accuracy, recall_3-vanilla_recall_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighting by Substrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3640/3640 [00:00<00:00, 6572.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substrate: 0.5971487376198034 0.7002747252747252 0.8673076923076923\n",
      "Substrate dif: 0.010735035680619398 0.007692307692307665 0.0019230769230769162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "wrong_predictions_S = []\n",
    "weighted_predictions_S = []\n",
    "weighted_predictions_raw_S = []\n",
    "prior_ratio_S = []\n",
    "\n",
    "for lbl, preds, sub in tqdm.tqdm(zip(GT_lbls, preds_raw, subs), total=len(GT_lbls)):\n",
    "\n",
    "    substrate_dist = substrate_distributions[sub]\n",
    "    preds = softmax(preds)\n",
    "    \n",
    "    p_substrate = (preds * substrate_dist) / sum(preds * substrate_dist)\n",
    "    prior_ratio = p_substrate / class_priors\n",
    "    max_index = np.argmax(prior_ratio * preds)     \n",
    "    \n",
    "    prior_ratio_S.append(prior_ratio)\n",
    "    weighted_predictions_raw_S.append(prior_ratio * preds)\n",
    "    weighted_predictions_S.append(max_index)\n",
    "    \n",
    "    if lbl != max_index:\n",
    "        wrong_predictions_S.append([lbl, sub])\n",
    "        \n",
    "f1 = f1_score(test_metadata_genera['class_id'], weighted_predictions_S, average='macro')\n",
    "accuracy = accuracy_score(test_metadata_genera['class_id'], weighted_predictions_S)\n",
    "recall_3 = top_k_accuracy_score(test_metadata_genera['class_id'], weighted_predictions_raw_S, k=3)\n",
    "print('Substrate:', f1, accuracy, recall_3)\n",
    "print('Substrate dif:', f1-vanilla_f1, accuracy-vanilla_accuracy, recall_3-vanilla_recall_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighting by Month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3640/3640 [00:00<00:00, 5532.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Month: 0.600374301036281 0.701098901098901 0.8722527472527473\n",
      "Month dif: 0.013960599097097015 0.008516483516483486 0.006868131868131844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "wrong_predictions_M = []\n",
    "weighted_predictions_M = []\n",
    "weighted_predictions_raw_M = []\n",
    "prior_ratio_M = []\n",
    "\n",
    "for lbl, preds, month in tqdm.tqdm(zip(GT_lbls, preds_raw, months), total=len(GT_lbls)):\n",
    "    \n",
    "    month_dist = month_distributions[str(float(month))]\n",
    "    preds = softmax(preds)\n",
    "    \n",
    "    p_month = (preds * month_dist) / sum(preds * month_dist)\n",
    "    prior_ratio = p_month / class_priors        \n",
    "    max_index = np.argmax(prior_ratio * preds)     \n",
    "    \n",
    "    prior_ratio_M.append(prior_ratio)\n",
    "    weighted_predictions_raw_M.append(prior_ratio * preds)\n",
    "    weighted_predictions_M.append(max_index)\n",
    "    \n",
    "    if lbl != max_index:\n",
    "        wrong_predictions_M.append([lbl, month])\n",
    "\n",
    "f1 = f1_score(test_metadata_genera['class_id'], weighted_predictions_M, average='macro')\n",
    "accuracy = accuracy_score(test_metadata_genera['class_id'], weighted_predictions_M)\n",
    "recall_3 = top_k_accuracy_score(test_metadata_genera['class_id'], weighted_predictions_raw_M, k=3)\n",
    "print('Month:', f1, accuracy, recall_3)\n",
    "print('Month dif:', f1-vanilla_f1, accuracy-vanilla_accuracy, recall_3-vanilla_recall_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighting by Month and Substrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3640/3640 [00:00<00:00, 7405.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M+S: 0.6063674679875247 0.7054945054945055 0.8733516483516484\n",
      "M+S dif: 0.01995376604834076 0.012912087912087977 0.007967032967032939\n"
     ]
    }
   ],
   "source": [
    "from scipy.special import softmax\n",
    "\n",
    "merged_predictions = []\n",
    "merged_predictions_raw = []\n",
    "\n",
    "for o, m, s, h in tqdm.tqdm(zip(preds_raw, prior_ratio_M, prior_ratio_S, prior_ratio_H), total=len(prior_ratio_M)):\n",
    "    \n",
    "    preds = softmax(preds)\n",
    "        \n",
    "    m_pred = (preds * m * s) / sum(preds * m * s)\n",
    "    max_index = np.argmax(m_pred)\n",
    "    \n",
    "    merged_predictions_raw.append(m_pred)\n",
    "    merged_predictions.append(max_index)\n",
    "    \n",
    "f1 = f1_score(test_metadata_genera['class_id'], merged_predictions, average='macro')\n",
    "accuracy = accuracy_score(test_metadata_genera['class_id'], merged_predictions)\n",
    "recall_3 = top_k_accuracy_score(test_metadata_genera['class_id'], merged_predictions_raw, k=3)\n",
    "print('M+S:' , f1, accuracy, recall_3)\n",
    "print('M+S dif:', f1-vanilla_f1, accuracy-vanilla_accuracy, recall_3-vanilla_recall_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighting by Month and Habitat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3640/3640 [00:00<00:00, 7791.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M+H: 0.6290117827056498 0.720054945054945 0.8854395604395604\n",
      "M+H dif: 0.04259808076646587 0.027472527472527486 0.020054945054944984\n"
     ]
    }
   ],
   "source": [
    "merged_predictions = []\n",
    "merged_predictions_raw = []\n",
    "\n",
    "for o, m, s, h in tqdm.tqdm(zip(preds_raw, prior_ratio_M, prior_ratio_S, prior_ratio_H), total=len(prior_ratio_M)):\n",
    "    \n",
    "    preds = softmax(preds)\n",
    "    \n",
    "    m_pred = (preds * m * h) / sum((preds * m * h))\n",
    "    max_index = np.argmax(m_pred)\n",
    "    \n",
    "    merged_predictions_raw.append(m_pred)    \n",
    "    merged_predictions.append(max_index)\n",
    "\n",
    "f1 = f1_score(test_metadata_genera['class_id'], merged_predictions, average='macro')\n",
    "accuracy = accuracy_score(test_metadata_genera['class_id'], merged_predictions)\n",
    "recall_3 = top_k_accuracy_score(test_metadata_genera['class_id'], merged_predictions_raw, k=3)\n",
    "print('M+H:', f1, accuracy, recall_3)    \n",
    "print('M+H dif:', f1-vanilla_f1, accuracy-vanilla_accuracy, recall_3-vanilla_recall_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighting by Substrate and Habitat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3640/3640 [00:00<00:00, 7550.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S+H: 0.6234002590810134 0.7145604395604396 0.8777472527472527\n",
      "S+H dif: 0.03698655714182941 0.02197802197802201 0.012362637362637319\n"
     ]
    }
   ],
   "source": [
    "merged_predictions = []\n",
    "merged_predictions_raw = []\n",
    "\n",
    "for o, m, s, h in tqdm.tqdm(zip(preds_raw, prior_ratio_M, prior_ratio_S, prior_ratio_H), total=len(prior_ratio_M)):\n",
    "    \n",
    "    preds = softmax(preds)\n",
    "    \n",
    "    m_pred = (preds * s * h) / sum((preds * s * h))\n",
    "    max_index = np.argmax(m_pred)\n",
    "    \n",
    "    merged_predictions_raw.append(m_pred)    \n",
    "    merged_predictions.append(max_index)\n",
    "\n",
    "f1 = f1_score(test_metadata_genera['class_id'], merged_predictions, average='macro')\n",
    "accuracy = accuracy_score(test_metadata_genera['class_id'], merged_predictions)\n",
    "recall_3 = top_k_accuracy_score(test_metadata_genera['class_id'], merged_predictions_raw, k=3)\n",
    "print('S+H:' , f1, accuracy, recall_3)\n",
    "print('S+H dif:', f1-vanilla_f1, accuracy-vanilla_accuracy, recall_3-vanilla_recall_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighting by Month, Substrate and Habitat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3640/3640 [00:00<00:00, 7386.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All: 0.6330054459258191 0.7214285714285714 0.8818681318681318 0.9197802197802197 0.9505494505494505\n",
      "All dif: 0.046591743986635126 0.028846153846153855 0.016483516483516425\n"
     ]
    }
   ],
   "source": [
    "from scipy.special import softmax\n",
    "\n",
    "wrong_predictions_all = []\n",
    "merged_predictions = []\n",
    "merged_predictions_raw = []\n",
    "\n",
    "wrong_predictions_all_genus = []\n",
    "merged_predictions_genus = []\n",
    "\n",
    "for lbl, img_path, o, m, s, h in tqdm.tqdm(zip(GT_lbls, image_paths, preds_raw, prior_ratio_M, prior_ratio_S, prior_ratio_H), total=len(prior_ratio_M)):\n",
    "    \n",
    "    preds = softmax(preds)\n",
    " \n",
    "    m_pred = (preds * m * s * h) / sum((preds * m * s * h))\n",
    "    max_index = np.argmax(m_pred)\n",
    "    \n",
    "    merged_predictions_raw.append(m_pred)    \n",
    "    merged_predictions.append(max_index)\n",
    "    \n",
    "    merged_predictions_genus.append(class_to_genus[max_index])\n",
    "    \n",
    "    if lbl != max_index:\n",
    "        wrong_predictions_all.append([lbl, max_index, img_path])\n",
    "    \n",
    "        if class_to_genus[lbl] != class_to_genus[max_index]:\n",
    "            wrong_predictions_all_genus.append([lbl, max_index, img_path])\n",
    "            \n",
    "f1 = f1_score(test_metadata_genera['class_id'], merged_predictions, average='macro')\n",
    "accuracy = accuracy_score(test_metadata_genera['class_id'], merged_predictions)\n",
    "recall_3 = top_k_accuracy_score(test_metadata_genera['class_id'], merged_predictions_raw, k=3)\n",
    "recall_5 = top_k_accuracy_score(test_metadata_genera['class_id'], merged_predictions_raw, k=5)\n",
    "recall_10 = top_k_accuracy_score(test_metadata_genera['class_id'], merged_predictions_raw, k=10)\n",
    "\n",
    "print('All:', f1, accuracy, recall_3, recall_5, recall_10)\n",
    "print('All dif:', f1-vanilla_f1, accuracy-vanilla_accuracy, recall_3-vanilla_recall_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All: 0.9439925038189818 0.9543956043956044\n"
     ]
    }
   ],
   "source": [
    "f1 = f1_score(test_metadata_genera['genus_id'], merged_predictions_genus, average='macro')\n",
    "accuracy = accuracy_score(test_metadata_genera['genus_id'], merged_predictions_genus)\n",
    "print('All:', f1, accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
