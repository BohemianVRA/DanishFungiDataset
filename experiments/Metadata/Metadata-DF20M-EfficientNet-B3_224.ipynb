{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "import json\n",
    "import tqdm\n",
    "import time\n",
    "import timm\n",
    "import torch\n",
    "import random\n",
    "import sklearn.metrics\n",
    "\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from functools import partial\n",
    "from contextlib import contextmanager\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.optim import Adam, SGD\n",
    "from scipy.special import softmax\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from albumentations import Compose, Normalize, Resize\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from sklearn.metrics import f1_score, accuracy_score, top_k_accuracy_score\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Parsing Metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading metadata files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metadata_genera = pd.read_csv(\"/Datasets/SvampeAtlas-14.12.2020/metadata/DanishFungi2020-Mini_train_metadata_DEV.csv\")\n",
    "test_metadata_genera = pd.read_csv(\"/Datasets/SvampeAtlas-14.12.2020/metadata/DanishFungi2020-Mini_test_metadata_DEV.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32753 3640\n"
     ]
    }
   ],
   "source": [
    "print(len(train_metadata_genera), len(test_metadata_genera))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36393"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata = pd.concat([train_metadata_genera, test_metadata_genera])\n",
    "len(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metadata_genera.Habitat = test_metadata_genera.Habitat.replace(np.nan, 'unknown', regex=True)\n",
    "test_metadata_genera.Substrate = test_metadata_genera.Substrate.replace(np.nan, 'unknown', regex=True)\n",
    "# test_metadata.month = test_metadata.month.replace(np.nan, 'unknown', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metadata_genera.Habitat = train_metadata_genera.Habitat.replace(np.nan, 'unknown', regex=True)\n",
    "train_metadata_genera.Substrate = train_metadata_genera.Substrate.replace(np.nan, 'unknown', regex=True)\n",
    "# metadata.month = metadata.month.replace(np.nan, 0, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['dead wood (including bark)', 'soil', 'bark', 'cones',\n",
       "       'leaf or needle litter', 'wood', 'mosses', 'bark of living trees',\n",
       "       nan, 'stems of herbs, grass etc', 'wood chips or mulch', 'catkins',\n",
       "       'other substrate', 'dead stems of herbs, grass etc', 'peat mosses',\n",
       "       'fungi', 'faeces', 'wood and roots of living trees',\n",
       "       'living stems of herbs, grass etc', 'fruits', 'fire spot',\n",
       "       'lichens', 'living leaves', 'building stone (e.g. bricks)',\n",
       "       'liverworts'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata.Substrate.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_to_genus = np.zeros(len(train_metadata_genera['class_id'].unique()))\n",
    "for species in train_metadata_genera['class_id'].unique():\n",
    "    class_to_genus[species] = train_metadata_genera[train_metadata_genera['class_id'] == species]['genus_id'].unique()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Species distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_priors = np.zeros(len(train_metadata_genera['class_id'].unique()))\n",
    "for species in train_metadata_genera['class_id'].unique():\n",
    "    class_priors[species] = len(train_metadata_genera[train_metadata_genera['class_id'] == species])\n",
    "\n",
    "class_priors = class_priors/sum(class_priors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting species-month distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32753/32753 [00:02<00:00, 13737.60it/s]\n"
     ]
    }
   ],
   "source": [
    "month_distributions = {}\n",
    "\n",
    "for _, observation in tqdm.tqdm(train_metadata_genera.iterrows(), total=len(train_metadata_genera)):\n",
    "    month = str(observation.month)\n",
    "    class_id = observation.class_id\n",
    "    if month not in month_distributions:        \n",
    "        month_distributions[month] = np.zeros(len(train_metadata_genera['class_id'].unique()))\n",
    "    else:\n",
    "        month_distributions[month][class_id] += 1\n",
    "\n",
    "for key, value in month_distributions.items():\n",
    "    month_distributions[key] = value / sum(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting species-habitat distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32753/32753 [00:02<00:00, 13774.56it/s]\n",
      "<ipython-input-13-1980391a20f2>:12: RuntimeWarning: invalid value encountered in true_divide\n",
      "  habitat_distributions[key] = value / sum(value)\n"
     ]
    }
   ],
   "source": [
    "habitat_distributions = {}\n",
    "\n",
    "for _, observation in tqdm.tqdm(train_metadata_genera.iterrows(), total=len(train_metadata_genera)):\n",
    "    habitat = observation.Habitat\n",
    "    class_id = observation.class_id\n",
    "    if habitat not in habitat_distributions:        \n",
    "        habitat_distributions[habitat] = np.zeros(len(train_metadata_genera['class_id'].unique()))\n",
    "    else:\n",
    "        habitat_distributions[habitat][class_id] += 1\n",
    "\n",
    "for key, value in habitat_distributions.items():\n",
    "    habitat_distributions[key] = value / sum(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting species-substrate distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32753/32753 [00:02<00:00, 14006.37it/s]\n",
      "<ipython-input-14-eb67722e2d43>:12: RuntimeWarning: invalid value encountered in true_divide\n",
      "  substrate_distributions[key] = value / sum(value)\n"
     ]
    }
   ],
   "source": [
    "substrate_distributions = {}\n",
    "\n",
    "for _, observation in tqdm.tqdm(train_metadata_genera.iterrows(), total=len(train_metadata_genera)):\n",
    "    substrate = observation.Substrate\n",
    "    class_id = observation.class_id\n",
    "    if substrate not in substrate_distributions:        \n",
    "        substrate_distributions[substrate] = np.zeros(len(train_metadata_genera['class_id'].unique()))\n",
    "    else:\n",
    "        substrate_distributions[substrate][class_id] += 1\n",
    "\n",
    "for key, value in substrate_distributions.items():\n",
    "    substrate_distributions[key] = value / sum(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting with trained network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_torch(seed=777):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "SEED = 777\n",
    "seed_torch(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        file_path = self.df['image_path'].values[idx]\n",
    "        label = self.df['class_id'].values[idx]\n",
    "        month = self.df['month'].values[idx]\n",
    "        sub = self.df['Substrate'].values[idx]\n",
    "        hab = self.df['Habitat'].values[idx]\n",
    "        \n",
    "        image = cv2.imread(file_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image)\n",
    "            image = augmented['image']\n",
    "        return image, label, file_path, month, hab, sub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "WIDTH, HEIGHT = 224, 224\n",
    "\n",
    "def get_transforms():\n",
    "\n",
    "    return Compose([Resize(WIDTH, HEIGHT),\n",
    "                    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225],),\n",
    "                    ToTensorV2()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 182\n",
    "\n",
    "\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "model = EfficientNet.from_pretrained('efficientnet-b3')\n",
    "\n",
    "model._fc = nn.Linear(model._fc.in_features, NUM_CLASSES)\n",
    "model.load_state_dict(torch.load('../../checkpoints/DF20M-EfficientNet-B3-224-GENERA_best_accuracy.pth'))\n",
    "\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_dataset_genera = TestDataset(test_metadata_genera, test_metadata_genera['class_id'], transform=get_transforms())\n",
    "test_dataset = TestDataset(test_metadata_genera, transform=get_transforms())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "#test_loader_genera = DataLoader(test_dataset_genera, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 114/114 [00:48<00:00,  2.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vanilla: 0.5367488844867935 0.6689560439560439 0.8348901098901099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "avg_val_loss = 0.\n",
    "preds = np.zeros((len(test_metadata_genera)))\n",
    "GT_lbls = []\n",
    "image_paths = []\n",
    "preds_raw = []\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "months = []\n",
    "subs = []\n",
    "habitats = []\n",
    "\n",
    "for i, (images, labels, paths, M, H, S) in enumerate(tqdm.tqdm(test_loader, total=len(test_loader))):\n",
    "\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        y_preds = model(images)\n",
    "    preds[i * batch_size: (i+1) * batch_size] = y_preds.argmax(1).to('cpu').numpy()\n",
    "    GT_lbls.extend(labels.to('cpu').numpy())\n",
    "    preds_raw.extend(y_preds.to('cpu').numpy())\n",
    "    image_paths.extend(paths)\n",
    "    months.extend(M)\n",
    "    subs.extend(S)\n",
    "    habitats.extend(H)\n",
    "\n",
    "vanilla_f1 = f1_score(test_metadata_genera['class_id'], preds, average='macro')\n",
    "vanilla_accuracy = accuracy_score(test_metadata_genera['class_id'], preds)\n",
    "vanilla_recall_3 = top_k_accuracy_score(test_metadata_genera['class_id'], preds_raw, k=3)\n",
    "\n",
    "print('Vanilla:', vanilla_f1, vanilla_accuracy, vanilla_recall_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighting by Habitat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3640/3640 [00:00<00:00, 12736.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Habitat: 0.5846332417443885 0.6881868131868132 0.8532967032967033\n",
      "Habitat dif: 0.04788435725759499 0.019230769230769273 0.01840659340659334\n"
     ]
    }
   ],
   "source": [
    "wrong_predictions_H = []\n",
    "weighted_predictions_H = []\n",
    "weighted_predictions_raw_H = []\n",
    "prior_ratio_H = []\n",
    "\n",
    "for lbl, preds, hab in tqdm.tqdm(zip(GT_lbls, preds_raw, habitats), total=len(GT_lbls)):\n",
    "    \n",
    "    habitat_dist = habitat_distributions[hab]\n",
    "    preds = softmax(preds)\n",
    "    \n",
    "    p_habitat = (preds * habitat_dist) / sum(preds * habitat_dist)\n",
    "    prior_ratio = p_habitat / class_priors\n",
    "    max_index = np.argmax(prior_ratio * preds)        \n",
    "    \n",
    "    prior_ratio_H.append(prior_ratio)\n",
    "    weighted_predictions_raw_H.append(prior_ratio * preds)\n",
    "    weighted_predictions_H.append(max_index)\n",
    "    \n",
    "    if lbl != max_index:\n",
    "        wrong_predictions_H.append([lbl, hab])\n",
    "\n",
    "f1 = f1_score(test_metadata_genera['class_id'], weighted_predictions_H, average='macro')\n",
    "accuracy = accuracy_score(test_metadata_genera['class_id'], weighted_predictions_H)\n",
    "recall_3 = top_k_accuracy_score(test_metadata_genera['class_id'], weighted_predictions_raw_H, k=3)\n",
    "print('Habitat:', f1, accuracy, recall_3)\n",
    "print('Habitat dif:', f1-vanilla_f1, accuracy-vanilla_accuracy, recall_3-vanilla_recall_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighting by Substrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3640/3640 [00:00<00:00, 12306.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substrate: 0.5506785660491035 0.6755494505494506 0.8387362637362638\n",
      "Substrate dif: 0.013929681562310003 0.006593406593406681 0.0038461538461538325\n"
     ]
    }
   ],
   "source": [
    "wrong_predictions_S = []\n",
    "weighted_predictions_S = []\n",
    "weighted_predictions_raw_S = []\n",
    "prior_ratio_S = []\n",
    "\n",
    "for lbl, preds, sub in tqdm.tqdm(zip(GT_lbls, preds_raw, subs), total=len(GT_lbls)):\n",
    "\n",
    "    substrate_dist = substrate_distributions[sub]\n",
    "    preds = softmax(preds)\n",
    "    \n",
    "    p_substrate = (preds * substrate_dist) / sum(preds * substrate_dist)\n",
    "    prior_ratio = p_substrate / class_priors\n",
    "    max_index = np.argmax(prior_ratio * preds)     \n",
    "    \n",
    "    prior_ratio_S.append(prior_ratio)\n",
    "    weighted_predictions_raw_S.append(prior_ratio * preds)\n",
    "    weighted_predictions_S.append(max_index)\n",
    "    \n",
    "    if lbl != max_index:\n",
    "        wrong_predictions_S.append([lbl, sub])\n",
    "        \n",
    "f1 = f1_score(test_metadata_genera['class_id'], weighted_predictions_S, average='macro')\n",
    "accuracy = accuracy_score(test_metadata_genera['class_id'], weighted_predictions_S)\n",
    "recall_3 = top_k_accuracy_score(test_metadata_genera['class_id'], weighted_predictions_raw_S, k=3)\n",
    "print('Substrate:', f1, accuracy, recall_3)\n",
    "print('Substrate dif:', f1-vanilla_f1, accuracy-vanilla_accuracy, recall_3-vanilla_recall_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighting by Month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3640/3640 [00:00<00:00, 12235.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Month: 0.5681291828843478 0.6832417582417583 0.8467032967032967\n",
      "Month dif: 0.031380298397554296 0.014285714285714346 0.011813186813186771\n"
     ]
    }
   ],
   "source": [
    "wrong_predictions_M = []\n",
    "weighted_predictions_M = []\n",
    "weighted_predictions_raw_M = []\n",
    "prior_ratio_M = []\n",
    "\n",
    "for lbl, preds, month in tqdm.tqdm(zip(GT_lbls, preds_raw, months), total=len(GT_lbls)):\n",
    "    \n",
    "    month_dist = month_distributions[str(float(month))]\n",
    "    preds = softmax(preds)\n",
    "    \n",
    "    p_month = (preds * month_dist) / sum(preds * month_dist)\n",
    "    prior_ratio = p_month / class_priors        \n",
    "    max_index = np.argmax(prior_ratio * preds)     \n",
    "    \n",
    "    prior_ratio_M.append(prior_ratio)\n",
    "    weighted_predictions_raw_M.append(prior_ratio * preds)\n",
    "    weighted_predictions_M.append(max_index)\n",
    "    \n",
    "    if lbl != max_index:\n",
    "        wrong_predictions_M.append([lbl, month])\n",
    "\n",
    "f1 = f1_score(test_metadata_genera['class_id'], weighted_predictions_M, average='macro')\n",
    "accuracy = accuracy_score(test_metadata_genera['class_id'], weighted_predictions_M)\n",
    "recall_3 = top_k_accuracy_score(test_metadata_genera['class_id'], weighted_predictions_raw_M, k=3)\n",
    "print('Month:', f1, accuracy, recall_3)\n",
    "print('Month dif:', f1-vanilla_f1, accuracy-vanilla_accuracy, recall_3-vanilla_recall_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighting by Month and Substrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3640/3640 [00:00<00:00, 12146.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M+S: 0.5772118550629611 0.6887362637362637 0.8489010989010989\n",
      "M+S dif: 0.040462970576167656 0.01978021978021982 0.014010989010988961\n"
     ]
    }
   ],
   "source": [
    "from scipy.special import softmax\n",
    "\n",
    "merged_predictions = []\n",
    "merged_predictions_raw = []\n",
    "\n",
    "for o, m, s, h in tqdm.tqdm(zip(preds_raw, prior_ratio_M, prior_ratio_S, prior_ratio_H), total=len(prior_ratio_M)):\n",
    "    \n",
    "    preds = softmax(preds)\n",
    "        \n",
    "    m_pred = (preds * m * s) / sum(preds * m * s)\n",
    "    max_index = np.argmax(m_pred)\n",
    "    \n",
    "    merged_predictions_raw.append(m_pred)\n",
    "    merged_predictions.append(max_index)\n",
    "    \n",
    "f1 = f1_score(test_metadata_genera['class_id'], merged_predictions, average='macro')\n",
    "accuracy = accuracy_score(test_metadata_genera['class_id'], merged_predictions)\n",
    "recall_3 = top_k_accuracy_score(test_metadata_genera['class_id'], merged_predictions_raw, k=3)\n",
    "print('M+S:' , f1, accuracy, recall_3)\n",
    "print('M+S dif:', f1-vanilla_f1, accuracy-vanilla_accuracy, recall_3-vanilla_recall_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighting by Month and Habitat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3640/3640 [00:00<00:00, 12294.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M+H: 0.612410064050507 0.7057692307692308 0.8620879120879121\n",
      "M+H dif: 0.07566117956371354 0.036813186813186904 0.027197802197802212\n"
     ]
    }
   ],
   "source": [
    "merged_predictions = []\n",
    "merged_predictions_raw = []\n",
    "\n",
    "for o, m, s, h in tqdm.tqdm(zip(preds_raw, prior_ratio_M, prior_ratio_S, prior_ratio_H), total=len(prior_ratio_M)):\n",
    "    \n",
    "    preds = softmax(preds)\n",
    "    \n",
    "    m_pred = (preds * m * h) / sum((preds * m * h))\n",
    "    max_index = np.argmax(m_pred)\n",
    "    \n",
    "    merged_predictions_raw.append(m_pred)    \n",
    "    merged_predictions.append(max_index)\n",
    "\n",
    "f1 = f1_score(test_metadata_genera['class_id'], merged_predictions, average='macro')\n",
    "accuracy = accuracy_score(test_metadata_genera['class_id'], merged_predictions)\n",
    "recall_3 = top_k_accuracy_score(test_metadata_genera['class_id'], merged_predictions_raw, k=3)\n",
    "print('M+H:', f1, accuracy, recall_3)    \n",
    "print('M+H dif:', f1-vanilla_f1, accuracy-vanilla_accuracy, recall_3-vanilla_recall_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighting by Substrate and Habitat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3640/3640 [00:00<00:00, 12827.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S+H: 0.5927153578545372 0.6928571428571428 0.8546703296703296\n",
      "S+H dif: 0.05596647336774374 0.023901098901098927 0.01978021978021971\n"
     ]
    }
   ],
   "source": [
    "merged_predictions = []\n",
    "merged_predictions_raw = []\n",
    "\n",
    "for o, m, s, h in tqdm.tqdm(zip(preds_raw, prior_ratio_M, prior_ratio_S, prior_ratio_H), total=len(prior_ratio_M)):\n",
    "    \n",
    "    preds = softmax(preds)\n",
    "    \n",
    "    m_pred = (preds * s * h) / sum((preds * s * h))\n",
    "    max_index = np.argmax(m_pred)\n",
    "    \n",
    "    merged_predictions_raw.append(m_pred)    \n",
    "    merged_predictions.append(max_index)\n",
    "\n",
    "f1 = f1_score(test_metadata_genera['class_id'], merged_predictions, average='macro')\n",
    "accuracy = accuracy_score(test_metadata_genera['class_id'], merged_predictions)\n",
    "recall_3 = top_k_accuracy_score(test_metadata_genera['class_id'], merged_predictions_raw, k=3)\n",
    "print('S+H:' , f1, accuracy, recall_3)\n",
    "print('S+H dif:', f1-vanilla_f1, accuracy-vanilla_accuracy, recall_3-vanilla_recall_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighting by Month, Substrate and Habitat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3640/3640 [00:00<00:00, 11460.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All: 0.6099220252435588 0.7032967032967034 0.8596153846153847 0.9038461538461539 0.9436813186813187\n",
      "All dif: 0.07317314075676529 0.03434065934065944 0.02472527472527475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from scipy.special import softmax\n",
    "\n",
    "wrong_predictions_all = []\n",
    "merged_predictions = []\n",
    "merged_predictions_raw = []\n",
    "\n",
    "wrong_predictions_all_genus = []\n",
    "merged_predictions_genus = []\n",
    "\n",
    "for lbl, img_path, o, m, s, h in tqdm.tqdm(zip(GT_lbls, image_paths, preds_raw, prior_ratio_M, prior_ratio_S, prior_ratio_H), total=len(prior_ratio_M)):\n",
    "    \n",
    "    preds = softmax(preds)\n",
    " \n",
    "    m_pred = (preds * m * s * h) / sum((preds * m * s * h))\n",
    "    max_index = np.argmax(m_pred)\n",
    "    \n",
    "    merged_predictions_raw.append(m_pred)    \n",
    "    merged_predictions.append(max_index)\n",
    "    \n",
    "    merged_predictions_genus.append(class_to_genus[max_index])\n",
    "    \n",
    "    if lbl != max_index:\n",
    "        wrong_predictions_all.append([lbl, max_index, img_path])\n",
    "    \n",
    "        if class_to_genus[lbl] != class_to_genus[max_index]:\n",
    "            wrong_predictions_all_genus.append([lbl, max_index, img_path])\n",
    "            \n",
    "f1 = f1_score(test_metadata_genera['class_id'], merged_predictions, average='macro')\n",
    "accuracy = accuracy_score(test_metadata_genera['class_id'], merged_predictions)\n",
    "recall_3 = top_k_accuracy_score(test_metadata_genera['class_id'], merged_predictions_raw, k=3)\n",
    "recall_5 = top_k_accuracy_score(test_metadata_genera['class_id'], merged_predictions_raw, k=5)\n",
    "recall_10 = top_k_accuracy_score(test_metadata_genera['class_id'], merged_predictions_raw, k=10)\n",
    "\n",
    "print('All:', f1, accuracy, recall_3, recall_5, recall_10)\n",
    "print('All dif:', f1-vanilla_f1, accuracy-vanilla_accuracy, recall_3-vanilla_recall_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All: 0.9332625307964019 0.9456043956043956\n"
     ]
    }
   ],
   "source": [
    "f1 = f1_score(test_metadata_genera['genus_id'], merged_predictions_genus, average='macro')\n",
    "accuracy = accuracy_score(test_metadata_genera['genus_id'], merged_predictions_genus)\n",
    "print('All:', f1, accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
