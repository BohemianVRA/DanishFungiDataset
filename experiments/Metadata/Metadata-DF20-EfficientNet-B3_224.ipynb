{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "import json\n",
    "import tqdm\n",
    "import time\n",
    "import timm\n",
    "import torch\n",
    "import random\n",
    "import sklearn.metrics\n",
    "\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from functools import partial\n",
    "from contextlib import contextmanager\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.optim import Adam, SGD\n",
    "from scipy.special import softmax\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from albumentations import Compose, Normalize, Resize\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from sklearn.metrics import f1_score, accuracy_score, top_k_accuracy_score\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Parsing Metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading metadata files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metadata = pd.read_csv(\"/Datasets/SvampeAtlas-14.12.2020/metadata/DanishFungi2020_train_metadata_DEV.csv\")\n",
    "test_metadata = pd.read_csv(\"/Datasets/SvampeAtlas-14.12.2020/metadata/DanishFungi2020_test_metadata_DEV.csv\")\n",
    "test_metadata_genera = pd.read_csv(\"/Datasets/SvampeAtlas-14.12.2020/metadata/DanishFungi2020-Mini_test_metadata_DEV.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "266344 29594 3640\n"
     ]
    }
   ],
   "source": [
    "print(len(train_metadata), len(test_metadata), len(test_metadata_genera))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "295938"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata = pd.concat([train_metadata, test_metadata])\n",
    "len(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metadata.Habitat = test_metadata.Habitat.replace(np.nan, 'unknown', regex=True)\n",
    "test_metadata.Substrate = test_metadata.Substrate.replace(np.nan, 'unknown', regex=True)\n",
    "# test_metadata.month = test_metadata.month.replace(np.nan, 'unknown', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata.Habitat = metadata.Habitat.replace(np.nan, 'unknown', regex=True)\n",
    "metadata.Substrate = metadata.Substrate.replace(np.nan, 'unknown', regex=True)\n",
    "# metadata.month = metadata.month.replace(np.nan, 0, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['bark of living trees', 'dead wood (including bark)', 'soil',\n",
       "       'stone', 'leaf or needle litter', 'wood', 'living leaves', 'bark',\n",
       "       'siliceous stone', 'cones', 'peat mosses',\n",
       "       'stems of herbs, grass etc', 'building stone (e.g. bricks)',\n",
       "       'dead stems of herbs, grass etc', 'wood chips or mulch', 'unknown',\n",
       "       'wood and roots of living trees',\n",
       "       'living stems of herbs, grass etc', 'faeces', 'mosses', 'fungi',\n",
       "       'insects', 'fruits', 'fire spot', 'catkins', 'lichens',\n",
       "       'other substrate', 'calcareous stone', 'living flowers',\n",
       "       'remains of vertebrates (e.g. feathers and fur)', 'liverworts',\n",
       "       'mycetozoans'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata.Substrate.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_to_genus = np.zeros(len(metadata['class_id'].unique()))\n",
    "for species in metadata['class_id'].unique():\n",
    "    class_to_genus[species] = metadata[metadata['class_id'] == species]['genus_id'].unique()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Species distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_priors = np.zeros(len(metadata['class_id'].unique()))\n",
    "for species in metadata['class_id'].unique():\n",
    "    class_priors[species] = len(metadata[metadata['class_id'] == species])\n",
    "\n",
    "class_priors = class_priors/sum(class_priors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting species-month distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 295938/295938 [00:21<00:00, 13837.09it/s]\n"
     ]
    }
   ],
   "source": [
    "month_distributions = {}\n",
    "\n",
    "for _, observation in tqdm.tqdm(metadata.iterrows(), total=len(metadata)):\n",
    "    month = str(observation.month)\n",
    "    class_id = observation.class_id\n",
    "    if month not in month_distributions:        \n",
    "        month_distributions[month] = np.zeros(len(metadata['class_id'].unique()))\n",
    "    else:\n",
    "        month_distributions[month][class_id] += 1\n",
    "\n",
    "for key, value in month_distributions.items():\n",
    "    month_distributions[key] = value / sum(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting species-habitat distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 295938/295938 [00:21<00:00, 13903.63it/s]\n"
     ]
    }
   ],
   "source": [
    "habitat_distributions = {}\n",
    "\n",
    "for _, observation in tqdm.tqdm(metadata.iterrows(), total=len(metadata)):\n",
    "    habitat = observation.Habitat\n",
    "    class_id = observation.class_id\n",
    "    if habitat not in habitat_distributions:        \n",
    "        habitat_distributions[habitat] = np.zeros(len(metadata['class_id'].unique()))\n",
    "    else:\n",
    "        habitat_distributions[habitat][class_id] += 1\n",
    "\n",
    "for key, value in habitat_distributions.items():\n",
    "    habitat_distributions[key] = value / sum(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting species-substrate distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 295938/295938 [00:21<00:00, 13832.36it/s]\n"
     ]
    }
   ],
   "source": [
    "substrate_distributions = {}\n",
    "\n",
    "for _, observation in tqdm.tqdm(metadata.iterrows(), total=len(metadata)):\n",
    "    substrate = observation.Substrate\n",
    "    class_id = observation.class_id\n",
    "    if substrate not in substrate_distributions:        \n",
    "        substrate_distributions[substrate] = np.zeros(len(metadata['class_id'].unique()))\n",
    "    else:\n",
    "        substrate_distributions[substrate][class_id] += 1\n",
    "\n",
    "for key, value in substrate_distributions.items():\n",
    "    substrate_distributions[key] = value / sum(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting with trained network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_torch(seed=777):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "SEED = 777\n",
    "seed_torch(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        file_path = self.df['image_path'].values[idx]\n",
    "        label = self.df['class_id'].values[idx]\n",
    "        month = self.df['month'].values[idx]\n",
    "        sub = self.df['Substrate'].values[idx]\n",
    "        hab = self.df['Habitat'].values[idx]\n",
    "        \n",
    "        image = cv2.imread(file_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image)\n",
    "            image = augmented['image']\n",
    "        return image, label, file_path, month, hab, sub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "WIDTH, HEIGHT = 224, 224\n",
    "\n",
    "def get_transforms():\n",
    "\n",
    "    return Compose([Resize(WIDTH, HEIGHT),\n",
    "                    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225],),\n",
    "                    ToTensorV2()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 1604\n",
    "\n",
    "\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "model = EfficientNet.from_pretrained('efficientnet-b0')\n",
    "\n",
    "model._fc = nn.Linear(model._fc.in_features, NUM_CLASSES)\n",
    "model.load_state_dict(torch.load('../../checkpoints/DF20-EfficientNet-B0_best_accuracy.pth'))\n",
    "\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_dataset_genera = TestDataset(test_metadata_genera, test_metadata_genera['class_id'], transform=get_transforms())\n",
    "test_dataset = TestDataset(test_metadata, transform=get_transforms())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "#test_loader_genera = DataLoader(test_dataset_genera, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 463/463 [05:57<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vanilla: 0.5684921240794554 0.6590525106440495 0.8224640129756031\n"
     ]
    }
   ],
   "source": [
    "avg_val_loss = 0.\n",
    "preds = np.zeros((len(test_metadata)))\n",
    "GT_lbls = []\n",
    "image_paths = []\n",
    "preds_raw = []\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "months = []\n",
    "subs = []\n",
    "habitats = []\n",
    "\n",
    "for i, (images, labels, paths, M, H, S) in enumerate(tqdm.tqdm(test_loader, total=len(test_loader))):\n",
    "\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        y_preds = model(images)\n",
    "    preds[i * batch_size: (i+1) * batch_size] = y_preds.argmax(1).to('cpu').numpy()\n",
    "    GT_lbls.extend(labels.to('cpu').numpy())\n",
    "    preds_raw.extend(y_preds.to('cpu').numpy())\n",
    "    image_paths.extend(paths)\n",
    "    months.extend(M)\n",
    "    subs.extend(S)\n",
    "    habitats.extend(H)\n",
    "\n",
    "vanilla_f1 = f1_score(test_metadata['class_id'], preds, average='macro')\n",
    "vanilla_accuracy = accuracy_score(test_metadata['class_id'], preds)\n",
    "vanilla_recall_3 = top_k_accuracy_score(test_metadata['class_id'], preds_raw, k=3)\n",
    "\n",
    "print('Vanilla:', vanilla_f1, vanilla_accuracy, vanilla_recall_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighting by Habitat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29594/29594 [00:10<00:00, 2716.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Habitat: 0.6121738396572888 0.6853078326687843 0.848077312968845\n",
      "Habitat dif: 0.0436817155778334 0.026255322024734795 0.02561329999324191\n"
     ]
    }
   ],
   "source": [
    "wrong_predictions_H = []\n",
    "weighted_predictions_H = []\n",
    "weighted_predictions_raw_H = []\n",
    "prior_ratio_H = []\n",
    "\n",
    "for lbl, preds, hab in tqdm.tqdm(zip(GT_lbls, preds_raw, habitats), total=len(GT_lbls)):\n",
    "    \n",
    "    habitat_dist = habitat_distributions[hab]\n",
    "    preds = softmax(preds)\n",
    "    \n",
    "    p_habitat = (preds * habitat_dist) / sum(preds * habitat_dist)\n",
    "    prior_ratio = p_habitat / class_priors\n",
    "    max_index = np.argmax(prior_ratio * preds)        \n",
    "    \n",
    "    prior_ratio_H.append(prior_ratio)\n",
    "    weighted_predictions_raw_H.append(prior_ratio * preds)\n",
    "    weighted_predictions_H.append(max_index)\n",
    "    \n",
    "    if lbl != max_index:\n",
    "        wrong_predictions_H.append([lbl, hab])\n",
    "\n",
    "f1 = f1_score(test_metadata['class_id'], weighted_predictions_H, average='macro')\n",
    "accuracy = accuracy_score(test_metadata['class_id'], weighted_predictions_H)\n",
    "recall_3 = top_k_accuracy_score(test_metadata['class_id'], weighted_predictions_raw_H, k=3)\n",
    "print('Habitat:', f1, accuracy, recall_3)\n",
    "print('Habitat dif:', f1-vanilla_f1, accuracy-vanilla_accuracy, recall_3-vanilla_recall_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighting by Substrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29594/29594 [00:10<00:00, 2773.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substrate: 0.5994712645558894 0.6784821247550179 0.8401703047915118\n",
      "Substrate dif: 0.03097914047643402 0.01942961411096844 0.01770629181590866\n"
     ]
    }
   ],
   "source": [
    "wrong_predictions_S = []\n",
    "weighted_predictions_S = []\n",
    "weighted_predictions_raw_S = []\n",
    "prior_ratio_S = []\n",
    "\n",
    "for lbl, preds, sub in tqdm.tqdm(zip(GT_lbls, preds_raw, subs), total=len(GT_lbls)):\n",
    "\n",
    "    substrate_dist = substrate_distributions[sub]\n",
    "    preds = softmax(preds)\n",
    "    \n",
    "    p_substrate = (preds * substrate_dist) / sum(preds * substrate_dist)\n",
    "    prior_ratio = p_substrate / class_priors\n",
    "    max_index = np.argmax(prior_ratio * preds)     \n",
    "    \n",
    "    prior_ratio_S.append(prior_ratio)\n",
    "    weighted_predictions_raw_S.append(prior_ratio * preds)\n",
    "    weighted_predictions_S.append(max_index)\n",
    "    \n",
    "    if lbl != max_index:\n",
    "        wrong_predictions_S.append([lbl, sub])\n",
    "        \n",
    "f1 = f1_score(test_metadata['class_id'], weighted_predictions_S, average='macro')\n",
    "accuracy = accuracy_score(test_metadata['class_id'], weighted_predictions_S)\n",
    "recall_3 = top_k_accuracy_score(test_metadata['class_id'], weighted_predictions_raw_S, k=3)\n",
    "print('Substrate:', f1, accuracy, recall_3)\n",
    "print('Substrate dif:', f1-vanilla_f1, accuracy-vanilla_accuracy, recall_3-vanilla_recall_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighting by Month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29594/29594 [00:12<00:00, 2325.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Month: 0.5909418742168571 0.6750692707981347 0.8390214232614719\n",
      "Month dif: 0.02244975013740169 0.016016760154085263 0.016557410285868768\n"
     ]
    }
   ],
   "source": [
    "wrong_predictions_M = []\n",
    "weighted_predictions_M = []\n",
    "weighted_predictions_raw_M = []\n",
    "prior_ratio_M = []\n",
    "\n",
    "for lbl, preds, month in tqdm.tqdm(zip(GT_lbls, preds_raw, months), total=len(GT_lbls)):\n",
    "    \n",
    "    month_dist = month_distributions[str(float(month))]\n",
    "    preds = softmax(preds)\n",
    "    \n",
    "    p_month = (preds * month_dist) / sum(preds * month_dist)\n",
    "    prior_ratio = p_month / class_priors        \n",
    "    max_index = np.argmax(prior_ratio * preds)     \n",
    "    \n",
    "    prior_ratio_M.append(prior_ratio)\n",
    "    weighted_predictions_raw_M.append(prior_ratio * preds)\n",
    "    weighted_predictions_M.append(max_index)\n",
    "    \n",
    "    if lbl != max_index:\n",
    "        wrong_predictions_M.append([lbl, month])\n",
    "\n",
    "f1 = f1_score(test_metadata['class_id'], weighted_predictions_M, average='macro')\n",
    "accuracy = accuracy_score(test_metadata['class_id'], weighted_predictions_M)\n",
    "recall_3 = top_k_accuracy_score(test_metadata['class_id'], weighted_predictions_raw_M, k=3)\n",
    "print('Month:', f1, accuracy, recall_3)\n",
    "print('Month dif:', f1-vanilla_f1, accuracy-vanilla_accuracy, recall_3-vanilla_recall_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighting by Month and Substrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29594/29594 [00:13<00:00, 2239.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M+S: 0.6223293544675633 0.6940933973102656 0.8564911806447253\n",
      "M+S dif: 0.05383723038810795 0.03504088666621619 0.03402716766912217\n"
     ]
    }
   ],
   "source": [
    "from scipy.special import softmax\n",
    "\n",
    "merged_predictions = []\n",
    "merged_predictions_raw = []\n",
    "\n",
    "for o, m, s, h in tqdm.tqdm(zip(preds_raw, prior_ratio_M, prior_ratio_S, prior_ratio_H), total=len(prior_ratio_M)):\n",
    "    \n",
    "    preds = softmax(preds)\n",
    "        \n",
    "    m_pred = (preds * m * s) / sum(preds * m * s)\n",
    "    max_index = np.argmax(m_pred)\n",
    "    \n",
    "    merged_predictions_raw.append(m_pred)\n",
    "    merged_predictions.append(max_index)\n",
    "    \n",
    "f1 = f1_score(test_metadata['class_id'], merged_predictions, average='macro')\n",
    "accuracy = accuracy_score(test_metadata['class_id'], merged_predictions)\n",
    "recall_3 = top_k_accuracy_score(test_metadata['class_id'], merged_predictions_raw, k=3)\n",
    "print('M+S:' , f1, accuracy, recall_3)\n",
    "print('M+S dif:', f1-vanilla_f1, accuracy-vanilla_accuracy, recall_3-vanilla_recall_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighting by Month and Habitat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29594/29594 [00:12<00:00, 2327.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M+H: 0.6387567782394821 0.701358383456106 0.8627762384267081\n",
      "M+H dif: 0.0702646541600267 0.042305872812056555 0.04031222545110502\n"
     ]
    }
   ],
   "source": [
    "merged_predictions = []\n",
    "merged_predictions_raw = []\n",
    "\n",
    "for o, m, s, h in tqdm.tqdm(zip(preds_raw, prior_ratio_M, prior_ratio_S, prior_ratio_H), total=len(prior_ratio_M)):\n",
    "    \n",
    "    preds = softmax(preds)\n",
    "    \n",
    "    m_pred = (preds * m * h) / sum((preds * m * h))\n",
    "    max_index = np.argmax(m_pred)\n",
    "    \n",
    "    merged_predictions_raw.append(m_pred)    \n",
    "    merged_predictions.append(max_index)\n",
    "\n",
    "f1 = f1_score(test_metadata['class_id'], merged_predictions, average='macro')\n",
    "accuracy = accuracy_score(test_metadata['class_id'], merged_predictions)\n",
    "recall_3 = top_k_accuracy_score(test_metadata['class_id'], merged_predictions_raw, k=3)\n",
    "print('M+H:', f1, accuracy, recall_3)    \n",
    "print('M+H dif:', f1-vanilla_f1, accuracy-vanilla_accuracy, recall_3-vanilla_recall_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighting by Substrate and Habitat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29594/29594 [00:12<00:00, 2317.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S+H: 0.6418046227775008 0.7031830776508752 0.8640264918564574\n",
      "S+H dif: 0.07331249869804546 0.044130567006825716 0.04156247888085429\n"
     ]
    }
   ],
   "source": [
    "merged_predictions = []\n",
    "merged_predictions_raw = []\n",
    "\n",
    "for o, m, s, h in tqdm.tqdm(zip(preds_raw, prior_ratio_M, prior_ratio_S, prior_ratio_H), total=len(prior_ratio_M)):\n",
    "    \n",
    "    preds = softmax(preds)\n",
    "    \n",
    "    m_pred = (preds * s * h) / sum((preds * s * h))\n",
    "    max_index = np.argmax(m_pred)\n",
    "    \n",
    "    merged_predictions_raw.append(m_pred)    \n",
    "    merged_predictions.append(max_index)\n",
    "\n",
    "f1 = f1_score(test_metadata['class_id'], merged_predictions, average='macro')\n",
    "accuracy = accuracy_score(test_metadata['class_id'], merged_predictions)\n",
    "recall_3 = top_k_accuracy_score(test_metadata['class_id'], merged_predictions_raw, k=3)\n",
    "print('S+H:' , f1, accuracy, recall_3)\n",
    "print('S+H dif:', f1-vanilla_f1, accuracy-vanilla_accuracy, recall_3-vanilla_recall_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighting by Month, Substrate and Habitat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29594/29594 [00:10<00:00, 2700.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All: 0.655772280031751 0.710988713928499 0.8724065688991012 0.9120091910522403 0.9463404744204906\n",
      "All dif: 0.08728015595229566 0.05193620328444959 0.049942555923498055\n"
     ]
    }
   ],
   "source": [
    "from scipy.special import softmax\n",
    "\n",
    "wrong_predictions_all = []\n",
    "merged_predictions = []\n",
    "merged_predictions_raw = []\n",
    "\n",
    "wrong_predictions_all_genus = []\n",
    "merged_predictions_genus = []\n",
    "\n",
    "for lbl, img_path, o, m, s, h in tqdm.tqdm(zip(GT_lbls, image_paths, preds_raw, prior_ratio_M, prior_ratio_S, prior_ratio_H), total=len(prior_ratio_M)):\n",
    "    \n",
    "    preds = softmax(preds)\n",
    " \n",
    "    m_pred = (preds * m * s * h) / sum((preds * m * s * h))\n",
    "    max_index = np.argmax(m_pred)\n",
    "    \n",
    "    merged_predictions_raw.append(m_pred)    \n",
    "    merged_predictions.append(max_index)\n",
    "    \n",
    "    merged_predictions_genus.append(class_to_genus[max_index])\n",
    "    \n",
    "    if lbl != max_index:\n",
    "        wrong_predictions_all.append([lbl, max_index, img_path])\n",
    "    \n",
    "        if class_to_genus[lbl] != class_to_genus[max_index]:\n",
    "            wrong_predictions_all_genus.append([lbl, max_index, img_path])\n",
    "            \n",
    "f1 = f1_score(test_metadata['class_id'], merged_predictions, average='macro')\n",
    "accuracy = accuracy_score(test_metadata['class_id'], merged_predictions)\n",
    "recall_3 = top_k_accuracy_score(test_metadata['class_id'], merged_predictions_raw, k=3)\n",
    "recall_5 = top_k_accuracy_score(test_metadata['class_id'], merged_predictions_raw, k=5)\n",
    "recall_10 = top_k_accuracy_score(test_metadata['class_id'], merged_predictions_raw, k=10)\n",
    "\n",
    "print('All:', f1, accuracy, recall_3, recall_5, recall_10)\n",
    "print('All dif:', f1-vanilla_f1, accuracy-vanilla_accuracy, recall_3-vanilla_recall_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All: 0.734368922922385 0.8061093464891532\n"
     ]
    }
   ],
   "source": [
    "f1 = f1_score(test_metadata['genus_id'], merged_predictions_genus, average='macro')\n",
    "accuracy = accuracy_score(test_metadata['genus_id'], merged_predictions_genus)\n",
    "print('All:', f1, accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
