{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1e293cf-465c-4b94-9c85-93ecb12dd745",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "import os\n",
    "import os.path as osp\n",
    "import cv2\n",
    "import sys\n",
    "import json\n",
    "import tqdm\n",
    "import time\n",
    "import timm\n",
    "import torch\n",
    "import random\n",
    "import sklearn.metrics\n",
    "\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from functools import partial\n",
    "from contextlib import contextmanager\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.optim import Adam, SGD\n",
    "from scipy.special import softmax\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from albumentations import Compose, Normalize, Resize\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from sklearn.metrics import f1_score, accuracy_score, top_k_accuracy_score\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd60efcf-e97c-4657-a576-f5ed1df967b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d382a7a-a5ce-4362-aba4-4c00f14eb223",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_torch(seed=777):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "SEED = 777\n",
    "seed_torch(SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7dde24d7-4760-4d40-8e5b-2fcd187664dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import timm\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image\n",
    "from urllib.request import urlopen\n",
    "model = timm.create_model(\"hf-hub:BVRA/tf_efficientnet_b3.in1k_ft_df20m_224\", pretrained=True)\n",
    "model = model.eval()\n",
    "train_transforms = T.Compose([T.Resize(224), \n",
    "                              T.ToTensor(), \n",
    "                              T.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])]) \n",
    "\n",
    "# test_image_path = \"../data/DF20M/2237852193-58.JPG\"\n",
    "# img = Image.open(test_image_path)\n",
    "# output = model(train_transforms(img).unsqueeze(0))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1f87e85-f63a-49b6-bf0a-6a85868f15b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# softmax(output.detach().numpy()).max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92b7aab-adbf-473d-ae60-b5707c914528",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Using metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9784d510-d6a8-4806-a1ca-aac260a2cca8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../metadata/DanishFungi2023-train_mini.csv\")\n",
    "test_df = pd.read_csv(\"../metadata/DanishFungi2023-val_mini.csv\")\n",
    "# test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01965904-343f-414c-a6bb-2d23cd00ff17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "IMAGE_DIR = r\"C:\\Programming\\Python Projects\\Vision\\FungiCLEF\\data\\DF20M\"\n",
    "train_df[\"image_path\"] = train_df.image_path.apply(\n",
    "    lambda path: os.path.join(IMAGE_DIR, os.path.basename(path)))\n",
    "\n",
    "test_df[\"image_path\"] = test_df.image_path.apply(\n",
    "    lambda path: os.path.join(IMAGE_DIR, os.path.basename(path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53857034-a655-4aea-8fb0-10fc7126c025",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "label_encoders = {}\n",
    "columns_to_be_encoded = [\"Habitat\", \"Substrate\", \"MetaSubstrate\"]\n",
    "\n",
    "for column_name in columns_to_be_encoded:\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    label_encoders = {column_name: le}\n",
    "    \n",
    "    train_df[column_name] = le.fit_transform(train_df[column_name]).astype(np.int64)\n",
    "    test_df[column_name] = le.fit_transform(test_df[column_name]).astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20179253-763b-4310-b919-51cfbd86602f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36393"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata = pd.concat([train_df, test_df])\n",
    "len(metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edc81c6-4a02-4265-b511-10b563d1541d",
   "metadata": {},
   "source": [
    "# Calculating prios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86453c2d-c982-42ea-a1f2-6616e58f073d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_counts = metadata.groupby(\"class_id\").size()\n",
    "class_distribution = cls_counts / len(metadata)\n",
    "sum(class_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd79a272-2db3-4245-bf2c-f41baa52cbef",
   "metadata": {},
   "source": [
    "## Calculate Distributions of Selected Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15f5a032-bc52-42f1-ba52-1a481e65972a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SELECTED_FEATURES = [\"month\", \"Habitat\", \"Substrate\", \"MetaSubstrate\"]\n",
    "metadata_distributions = {}\n",
    "for feature in SELECTED_FEATURES:\n",
    "    distribution = metadata.groupby([feature, \"class_id\"]).size() / metadata.groupby(feature).size()\n",
    "    metadata_distributions[feature] = distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e139f486-6a29-46c2-9757-fbaca96dd24d",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7931d356-0161-49b9-a252-22d9964b7ce4",
   "metadata": {},
   "source": [
    "## Preparing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7fd9594b-efc2-4f65-815b-fa10d3249e84",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.485, 0.456, 0.406] [0.229, 0.224, 0.225]\n",
      "[0.5, 0.5, 0.5] [0.5, 0.5, 0.5]\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "N_CLASSES = len(metadata['class_id'].unique())\n",
    "IMAGE_SIZE = [224, 224]\n",
    "\n",
    "MODEL_NAME = \"BVRA/tf_efficientnet_b3.in1k_ft_df20m_224\"\n",
    "USE_CALIBRATION = True\n",
    "USE_OBSERVATION_PREDS = True\n",
    "\n",
    "model = timm.create_model(f\"hf-hub:{MODEL_NAME}\", pretrained=True)\n",
    "model = model.eval()\n",
    "model_mean = list(model.default_cfg['mean'])\n",
    "model_std = list(model.default_cfg['std'])\n",
    "print(model_mean, model_std)\n",
    "model_mean = [0.5, 0.5, 0.5]\n",
    "model_std = [0.5, 0.5, 0.5]\n",
    "print(model_mean, model_std)\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5364f28-94a5-4ba4-a302-ef73efc9306e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fgvc.special.calibration import ModelWithTemperature, get_temperature\n",
    "\n",
    "if USE_CALIBRATION:\n",
    "    model = ModelWithTemperature(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311b9f58-49d9-40cd-8c29-0a136051be56",
   "metadata": {},
   "source": [
    "## Prepare Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66398181-d466-4e60-986a-86a140be01d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset_cls import TestDataset, get_transforms\n",
    "test_dataset = TestDataset(test_df, [*SELECTED_FEATURES, \"observationID\"], transform=get_transforms(model_mean, model_std, IMAGE_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d1b84de4-6636-433c-af1f-d6f714af4a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b2299f-52a7-4ace-afd8-366c49b466e3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Vanilla Predictions without Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "29a61348-5559-47fe-9d22-33dee32c4ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                           | 0/58 [01:11<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[16], line 17\u001B[0m\n\u001B[0;32m     13\u001B[0m labels \u001B[38;5;241m=\u001B[39m labels\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m     16\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[1;32m---> 17\u001B[0m     y_preds \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimages\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     19\u001B[0m preds[i \u001B[38;5;241m*\u001B[39m batch_size: (i\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m) \u001B[38;5;241m*\u001B[39m batch_size] \u001B[38;5;241m=\u001B[39m y_preds\u001B[38;5;241m.\u001B[39margmax(\u001B[38;5;241m1\u001B[39m)\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;241m.\u001B[39mnumpy()\n\u001B[0;32m     20\u001B[0m GT_lbls\u001B[38;5;241m.\u001B[39mextend(labels\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;241m.\u001B[39mnumpy())\n",
      "File \u001B[1;32mc:\\programming\\python projects\\vision\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32mc:\\programming\\python projects\\vision\\venv\\lib\\site-packages\\fgvc\\special\\calibration.py:26\u001B[0m, in \u001B[0;36mModelWithTemperature.forward\u001B[1;34m(self, x, *args, **kwargs)\u001B[0m\n\u001B[0;32m     24\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Apply forward pass on the model and scale output logits.\"\"\"\u001B[39;00m\n\u001B[0;32m     25\u001B[0m logits \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel(x, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m---> 26\u001B[0m scaled_logits \u001B[38;5;241m=\u001B[39m \u001B[43mlogits\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtemperature\u001B[49m\n\u001B[0;32m     27\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m scaled_logits\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
     ]
    }
   ],
   "source": [
    "avg_val_loss = 0.\n",
    "preds = np.zeros((len(test_df)))\n",
    "GT_lbls = []\n",
    "image_paths = []\n",
    "preds_raw = []\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "seen_features = {feature: [] for feature in [*SELECTED_FEATURES, \"observationID\"]}\n",
    "\n",
    "for i, (images, labels, paths, selected_features) in enumerate(tqdm.tqdm(test_loader, total=len(test_loader))):\n",
    "\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "    \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        y_preds = model(images)\n",
    "        \n",
    "    preds[i * batch_size: (i+1) * batch_size] = y_preds.argmax(1).to('cpu').numpy()\n",
    "    GT_lbls.extend(labels.to('cpu').numpy())\n",
    "    preds_raw.extend(y_preds.to('cpu').numpy())\n",
    "    image_paths.extend(paths)\n",
    "    \n",
    "    for feature in [*SELECTED_FEATURES, \"observationID\"]:\n",
    "        seen_features[feature].extend(selected_features[feature])\n",
    "\n",
    "vanilla_f1 = f1_score(test_df['class_id'], preds, average='macro')\n",
    "vanilla_accuracy = accuracy_score(test_df['class_id'], preds)\n",
    "vanilla_recall_3 = top_k_accuracy_score(test_df['class_id'], preds_raw, k=3)\n",
    "vanilla_recall_5 = top_k_accuracy_score(test_df['class_id'], preds_raw, k=5)\n",
    "vanilla_recall_10 = top_k_accuracy_score(test_df['class_id'], preds_raw, k=10)\n",
    "\n",
    "print('Vanilla:', vanilla_f1, vanilla_accuracy, vanilla_recall_3, vanilla_recall_5, vanilla_recall_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923847f4-200e-44f6-922c-11d5e2736518",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "seen_observation_ids = np.array(seen_features[\"observationID\"])\n",
    "unique_observation_ids = np.unique(seen_observation_ids)\n",
    "\n",
    "preds_raw_np = np.array(preds_raw)\n",
    "\n",
    "obs_preds_raw = np.zeros((len(test_df), N_CLASSES))\n",
    "obs_preds = np.zeros((len(test_df)))\n",
    "\n",
    "for unique_observation_id in unique_observation_ids:\n",
    "    same_observation_indexes = np.where(seen_observation_ids == unique_observation_id)\n",
    "    \n",
    "    observation_predictions = preds_raw_np[same_observation_indexes]\n",
    "    # print(np.average(observation_predictions, axis=0))\n",
    "    _obs_preds = np.average(observation_predictions, axis=0)\n",
    "    \n",
    "    obs_preds_raw[same_observation_indexes] = _obs_preds\n",
    "    \n",
    "    \n",
    "    obs_preds[same_observation_indexes] = _obs_preds.argmax()\n",
    "    \n",
    "obs_f1 = f1_score(test_df['class_id'], obs_preds, average='macro')\n",
    "obs_accuracy = accuracy_score(test_df['class_id'], obs_preds)\n",
    "obs_recall_3 = top_k_accuracy_score(test_df['class_id'], obs_preds_raw, k=3)\n",
    "\n",
    "print('ObservationID:', obs_f1, obs_accuracy, obs_recall_3)\n",
    "\n",
    "if USE_OBSERVATION_PREDS:\n",
    "    vanilla_f1 = obs_f1\n",
    "    vanilla_accuracy = obs_accuracy\n",
    "    vanilla_recall_3 = obs_recall_3\n",
    "    preds_raw = obs_preds_raw\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889d0d2f-5a40-4926-9c73-b4a832c21b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature = get_temperature(\n",
    "    logits=np.array(preds_raw),\n",
    "    targs=np.array(GT_lbls)\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e35c4f-787b-4fcd-868b-ec6e2aa483da",
   "metadata": {},
   "source": [
    "## Weighting by each Selected Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d6ceb2-9d69-4132-8a3d-9d9f88b84f40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "EPSILON_DIVISION_NUMERIC_CHECK = 1e-12\n",
    "\n",
    "def post_process_by_feature(metadata_distribution, class_distribution, ground_truth_labels, raw_predictions, seen_feature_values):\n",
    "    wrong_predictions = []\n",
    "    weighted_predictions = []\n",
    "    weighted_predictions_raw = []\n",
    "    feature_prior_ratio = []\n",
    "\n",
    "    for lbl, raw_prediction, seen_feature in tqdm.tqdm(zip(ground_truth_labels, raw_predictions, seen_feature_values), total=len(ground_truth_labels)):\n",
    "        preds = softmax(raw_prediction)\n",
    "        # Add empty distributions\n",
    "        local_feature_distribution = np.ones(len(preds))\n",
    "        precomputed_seen_feature_distribution = metadata_distribution[int(seen_feature)]\n",
    "        local_feature_distribution[precomputed_seen_feature_distribution.index] = precomputed_seen_feature_distribution\n",
    "\n",
    "        p_feature = (preds * local_feature_distribution) / (sum(preds * local_feature_distribution))\n",
    "\n",
    "\n",
    "        prior_ratio = p_feature / class_distribution        \n",
    "        max_index = np.argmax(prior_ratio * preds)     \n",
    "\n",
    "\n",
    "        feature_prior_ratio.append(prior_ratio)\n",
    "        weighted_predictions_raw.append(prior_ratio * preds)\n",
    "        weighted_predictions.append(max_index)\n",
    "\n",
    "        if lbl != max_index:\n",
    "            wrong_predictions.append([lbl, seen_feature])\n",
    "            \n",
    "    return feature_prior_ratio, weighted_predictions, weighted_predictions_raw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b4c66f-7c51-417d-80ee-4aab02f8fdc9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def post_process_selected_features(metadata_distributions, class_distribution, raw_predictions, ground_truth_labels):\n",
    "    feature_prior_ratios = {}\n",
    "    metrics_by_features = {}\n",
    "    for feature in SELECTED_FEATURES:\n",
    "        metadata_distribution = metadata_distributions[feature]\n",
    "        seen_feature_values = seen_features[feature]\n",
    "\n",
    "        feature_prior_ratio, weighted_predictions, weighted_predictions_raw = post_process_by_feature(\n",
    "            metadata_distribution=metadata_distribution,\n",
    "            class_distribution=class_distribution,\n",
    "            ground_truth_labels=ground_truth_labels,\n",
    "            raw_predictions=raw_predictions,\n",
    "            seen_feature_values=seen_feature_values\n",
    "        )\n",
    "        feature_prior_ratios[feature] = feature_prior_ratio\n",
    "\n",
    "        f1 = f1_score(test_df['class_id'], weighted_predictions, average='macro')\n",
    "        accuracy = accuracy_score(test_df['class_id'], weighted_predictions)\n",
    "        recall_3 = top_k_accuracy_score(test_df['class_id'], weighted_predictions_raw, k=3)\n",
    "        metrics_by_features[feature] = {\n",
    "            \"f1\": f1,\n",
    "            \"accuracy\": accuracy,\n",
    "            \"recall_3\": recall_3\n",
    "        }\n",
    "        print(f'{feature}:', f1, accuracy, recall_3)\n",
    "        print(f'{feature} dif:', np.around(f1-vanilla_f1, 3), np.around((accuracy-vanilla_accuracy) * 100, 2), np.around((recall_3-vanilla_recall_3)*100))\n",
    "    \n",
    "    return feature_prior_ratios, metrics_by_features\n",
    "        \n",
    "feature_prior_ratios, metrics_by_features = post_process_selected_features(\n",
    "    metadata_distributions=metadata_distributions,\n",
    "    class_distribution=class_distribution,\n",
    "    raw_predictions=preds_raw,\n",
    "    ground_truth_labels=GT_lbls\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97662dea-8eb6-4bd2-8372-d247ecdbcf5a",
   "metadata": {},
   "source": [
    "## Weighting by Combinations of Selected Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557b8dfe-b761-4449-8a8b-b412353ac786",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def post_process_combine_priors(raw_predictions, selected_feature_prior_ratios: list):\n",
    "    merged_predictions = []\n",
    "    merged_predictions_raw = []\n",
    "    \n",
    "    for index, raw_prediction in enumerate(raw_predictions):\n",
    "        prediction = softmax(raw_prediction)\n",
    "        \n",
    "        \n",
    "        weighted_prediction = prediction\n",
    "        for feature_prior_ratio in selected_feature_prior_ratios:\n",
    "            weighted_prediction *= feature_prior_ratio[index]\n",
    "        \n",
    "        merged_prediction = weighted_prediction / (sum(weighted_prediction))\n",
    "        max_index = np.argmax(merged_prediction)\n",
    "        \n",
    "        merged_predictions_raw.append(merged_prediction)\n",
    "        merged_predictions.append(max_index)\n",
    "        \n",
    "    return merged_predictions, merged_predictions_raw\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71b7a56-6592-49e1-8b3b-9a0fa61e4afd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "\n",
    "def post_process_prior_combinations(raw_predictions, feature_prior_ratios):\n",
    "    metrics_by_combination = {}\n",
    "    all_combinations_selected_features = []\n",
    "    for r in range(2, len(SELECTED_FEATURES) + 1):\n",
    "        all_combinations_selected_features.extend(combinations(SELECTED_FEATURES, r))\n",
    "    \n",
    "    for combination in all_combinations_selected_features:\n",
    "\n",
    "        selected_feature_prior_ratios = [feature_prior_ratios[feature] for feature in combination]\n",
    "\n",
    "        merged_predictions, merged_predictions_raw = post_process_combine_priors(\n",
    "            raw_predictions=preds_raw,\n",
    "            selected_feature_prior_ratios=selected_feature_prior_ratios\n",
    "        )\n",
    "\n",
    "        f1 = f1_score(test_df['class_id'], merged_predictions, average='macro')\n",
    "        accuracy = accuracy_score(test_df['class_id'], merged_predictions)\n",
    "        recall_3 = top_k_accuracy_score(test_df['class_id'], merged_predictions_raw, k=3)\n",
    "        \n",
    "        combination_name = \" + \".join(combination)\n",
    "        \n",
    "        metrics_by_combination[combination_name] = {\n",
    "            \"f1\": f1,\n",
    "            \"accuracy\": accuracy,\n",
    "            \"recall_3\": recall_3\n",
    "        }\n",
    "        print(combination_name)\n",
    "        print(\"F1, Acc, Recall3: \", f1, accuracy, recall_3)\n",
    "        print(\"Diff: \", np.around(f1-vanilla_f1, 3), np.around((accuracy-vanilla_accuracy) * 100, 2), np.around((recall_3-vanilla_recall_3)*100, 2))\n",
    "    \n",
    "    return metrics_by_combination\n",
    "        \n",
    "metrics_by_combination = post_process_prior_combinations(\n",
    "    raw_predictions=preds_raw,\n",
    "    feature_prior_ratios=feature_prior_ratios\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd261d5-1757-4b56-ab7c-787058e719f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "results = {\"Vanilla\": {'f1': vanilla_f1, 'accuracy': vanilla_accuracy, 'recall_3': vanilla_recall_3}}\n",
    "results.update(metrics_by_features)\n",
    "results.update(metrics_by_combination)\n",
    "\n",
    "results_df = pd.DataFrame(results).transpose()\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab97de84-1265-4545-bbd0-3f3516b69aba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_path = f\"../output/PP-{MODEL_NAME}.txt\"\n",
    "\n",
    "output_msg = f\"{MODEL_NAME}, Calibration: {USE_CALIBRATION}, Observation: {USE_OBSERVATION_PREDS}\\n{results_df.to_markdown()}\\n\\n\"\n",
    "\n",
    "with open(output_path, \"a\") as fp:\n",
    "    fp.write(output_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038ebccc-3603-432b-856d-0d3d3a37c191",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
