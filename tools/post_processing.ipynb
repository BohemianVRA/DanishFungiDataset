{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e293cf-465c-4b94-9c85-93ecb12dd745",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tqdm\n",
    "import timm\n",
    "import torch\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import f1_score, accuracy_score, top_k_accuracy_score\n",
    "from fgvc.utils.utils import set_random_seed\n",
    "from fgvc.utils.utils import set_cuda_device\n",
    "\n",
    "device = set_cuda_device('0')\n",
    "print(f'Device: {device}')\n",
    "\n",
    "SEED = 777\n",
    "set_random_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd60efcf-e97c-4657-a576-f5ed1df967b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92b7aab-adbf-473d-ae60-b5707c914528",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Using metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9784d510-d6a8-4806-a1ca-aac260a2cca8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../metadata/DanishFungi2023-train_mini.csv\")\n",
    "test_df = pd.read_csv(\"../metadata/DanishFungi2023-val_mini.csv\")\n",
    "\n",
    "TARGET_FEATURE = \"class_id\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01965904-343f-414c-a6bb-2d23cd00ff17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "IMAGE_DIR = \"/home/marek/Projects/PythonLand/Vision/Baseline/data/DF20M\"\n",
    "train_df[\"image_path\"] = train_df.image_path.apply(\n",
    "    lambda path: os.path.join(IMAGE_DIR, os.path.basename(path)))\n",
    "\n",
    "test_df[\"image_path\"] = test_df.image_path.apply(\n",
    "    lambda path: os.path.join(IMAGE_DIR, os.path.basename(path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53857034-a655-4aea-8fb0-10fc7126c025",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "label_encoders = {}\n",
    "columns_to_be_encoded = [\"Habitat\", \"Substrate\"]\n",
    "\n",
    "for column_name in columns_to_be_encoded:\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    label_encoders = {column_name: le}\n",
    "    \n",
    "    train_df[column_name] = le.fit_transform(train_df[column_name]).astype(np.int64)\n",
    "    test_df[column_name] = le.fit_transform(test_df[column_name]).astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20179253-763b-4310-b919-51cfbd86602f",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.concat([train_df, test_df])\n",
    "len(metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edc81c6-4a02-4265-b511-10b563d1541d",
   "metadata": {},
   "source": [
    "# Calculating prios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86453c2d-c982-42ea-a1f2-6616e58f073d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_counts = metadata.groupby(TARGET_FEATURE).size()\n",
    "class_distribution = cls_counts / len(metadata)\n",
    "sum(class_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd79a272-2db3-4245-bf2c-f41baa52cbef",
   "metadata": {},
   "source": [
    "## Calculate Distributions of Selected Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f5a032-bc52-42f1-ba52-1a481e65972a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from postprocessing import get_target_to_feature_conditional_distributions\n",
    "SELECTED_FEATURES = [\"Habitat\", \"month\", \"Substrate\"]\n",
    "\n",
    "# test_df = test_df[~test_df[SELECTED_FEATURES].isna().any(axis=1)]\n",
    "\n",
    "metadata_distributions = {}\n",
    "for feature in SELECTED_FEATURES:\n",
    "    metadata_distributions[feature] = get_target_to_feature_conditional_distributions(\n",
    "        metadata,\n",
    "        feature,\n",
    "        TARGET_FEATURE,\n",
    "        add_to_missing=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e139f486-6a29-46c2-9757-fbaca96dd24d",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7931d356-0161-49b9-a252-22d9964b7ce4",
   "metadata": {},
   "source": [
    "## Preparing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd9594b-efc2-4f65-815b-fa10d3249e84",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "N_CLASSES = len(metadata[TARGET_FEATURE].unique())\n",
    "IMAGE_SIZE = [224, 224]\n",
    "\n",
    "MODEL_NAME = \"BVRA/vit_base_patch16_224.ft_df20m_224\"\n",
    "USE_CALIBRATION = True\n",
    "USE_OBSERVATION_PREDS = True\n",
    "\n",
    "model = timm.create_model(f\"hf-hub:{MODEL_NAME}\", pretrained=True)\n",
    "model = model.eval()\n",
    "\n",
    "# model_mean = list(model.default_cfg['mean'])\n",
    "# model_std = list(model.default_cfg['std'])\n",
    "# print(model_mean, model_std)\n",
    "model_mean = [0.5, 0.5, 0.5]\n",
    "model_std = [0.5, 0.5, 0.5]\n",
    "print(model_mean, model_std)\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n",
    "print(f\"Done. {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5364f28-94a5-4ba4-a302-ef73efc9306e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fgvc.special.calibration import ModelWithTemperature, get_temperature\n",
    "\n",
    "if USE_CALIBRATION:\n",
    "    model = ModelWithTemperature(model)\n",
    "    model.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311b9f58-49d9-40cd-8c29-0a136051be56",
   "metadata": {},
   "source": [
    "## Prepare Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66398181-d466-4e60-986a-86a140be01d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset_cls import ExtraFeaturesDataset, get_transforms\n",
    "test_dataset = ExtraFeaturesDataset(\n",
    "    test_df,\n",
    "    image_path_feature='image_path',\n",
    "    target_feature=TARGET_FEATURE,\n",
    "    extra_features=[*SELECTED_FEATURES, \"observationID\"], \n",
    "    transform=get_transforms(model_mean, model_std, IMAGE_SIZE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b84de4-6636-433c-af1f-d6f714af4a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b2299f-52a7-4ace-afd8-366c49b466e3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Vanilla Predictions without Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a61348-5559-47fe-9d22-33dee32c4ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from postprocessing import predict_with_features\n",
    "\n",
    "\n",
    "preds, preds_raw, GT_lbls, seen_features = predict_with_features(model, test_loader, device)\n",
    "\n",
    "vanilla_f1 = f1_score(test_df[TARGET_FEATURE], preds, average='macro')\n",
    "vanilla_accuracy = accuracy_score(test_df[TARGET_FEATURE], preds)\n",
    "vanilla_recall_3 = top_k_accuracy_score(test_df[TARGET_FEATURE], preds_raw, k=3)\n",
    "vanilla_recall_5 = top_k_accuracy_score(test_df[TARGET_FEATURE], preds_raw, k=5)\n",
    "vanilla_recall_10 = top_k_accuracy_score(test_df[TARGET_FEATURE], preds_raw, k=10)\n",
    "\n",
    "print('Vanilla:', vanilla_f1, vanilla_accuracy, vanilla_recall_3, vanilla_recall_5, vanilla_recall_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923847f4-200e-44f6-922c-11d5e2736518",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "seen_observation_ids = np.array(seen_features[\"observationID\"])\n",
    "unique_observation_ids = np.unique(seen_observation_ids)\n",
    "\n",
    "preds_raw_np = np.array(preds_raw)\n",
    "\n",
    "obs_preds_raw = np.zeros((len(test_df), N_CLASSES))\n",
    "obs_preds = np.zeros((len(test_df)))\n",
    "\n",
    "for unique_observation_id in unique_observation_ids:\n",
    "    same_observation_indexes = np.where(seen_observation_ids == unique_observation_id)\n",
    "    \n",
    "    observation_predictions = preds_raw_np[same_observation_indexes]\n",
    "    \n",
    "    _obs_preds = np.average(observation_predictions, axis=0)\n",
    "    \n",
    "    obs_preds_raw[same_observation_indexes] = _obs_preds\n",
    "    \n",
    "    obs_preds[same_observation_indexes] = _obs_preds.argmax()\n",
    "    \n",
    "obs_f1 = f1_score(test_df[TARGET_FEATURE], obs_preds, average='macro')\n",
    "obs_accuracy = accuracy_score(test_df[TARGET_FEATURE], obs_preds)\n",
    "obs_recall_3 = top_k_accuracy_score(test_df[TARGET_FEATURE], obs_preds_raw, k=3)\n",
    "\n",
    "print('ObservationID:', obs_f1, obs_accuracy, obs_recall_3)\n",
    "\n",
    "if USE_OBSERVATION_PREDS:\n",
    "    vanilla_f1 = obs_f1\n",
    "    vanilla_accuracy = obs_accuracy\n",
    "    vanilla_recall_3 = obs_recall_3\n",
    "    preds_raw = obs_preds_raw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889d0d2f-5a40-4926-9c73-b4a832c21b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature = get_temperature(\n",
    "    logits=np.array(preds_raw),\n",
    "    targs=np.array(GT_lbls)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e35c4f-787b-4fcd-868b-ec6e2aa483da",
   "metadata": {},
   "source": [
    "## Weighting by each Selected Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b4c66f-7c51-417d-80ee-4aab02f8fdc9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from postprocessing import weight_predictions_by_feature_distribution\n",
    "\n",
    "def post_process_selected_features(metadata_distributions, class_distribution, raw_predictions, ground_truth_labels):\n",
    "    feature_prior_ratios = {}\n",
    "    metrics_by_features = {}\n",
    "    for feature in SELECTED_FEATURES:\n",
    "        metadata_distribution = metadata_distributions[feature]\n",
    "        seen_feature_values = seen_features[feature]\n",
    "\n",
    "        weighted_predictions, weighted_predictions_raw, feature_prior_ratio = weight_predictions_by_feature_distribution(\n",
    "            target_to_feature_conditional_distributions=metadata_distribution,\n",
    "            target_distribution=class_distribution,\n",
    "            ground_truth_labels=ground_truth_labels,\n",
    "            raw_predictions=raw_predictions,\n",
    "            ground_truth_feature_categories=seen_feature_values\n",
    "        )\n",
    "        feature_prior_ratios[feature] = feature_prior_ratio\n",
    "\n",
    "        f1 = f1_score(test_df[TARGET_FEATURE], weighted_predictions, average='macro')\n",
    "        accuracy = accuracy_score(test_df[TARGET_FEATURE], weighted_predictions)\n",
    "        recall_3 = top_k_accuracy_score(test_df[TARGET_FEATURE], weighted_predictions_raw, k=3)\n",
    "        metrics_by_features[feature] = {\n",
    "            \"f1\": f1,\n",
    "            \"accuracy\": accuracy,\n",
    "            \"recall_3\": recall_3\n",
    "        }\n",
    "        print(f'{feature}:', f1, accuracy, recall_3)\n",
    "        print(f'{feature} dif:', np.around(f1-vanilla_f1, 3), np.around((accuracy-vanilla_accuracy) * 100, 2), np.around((recall_3-vanilla_recall_3)*100))\n",
    "    \n",
    "    return feature_prior_ratios, metrics_by_features\n",
    "        \n",
    "feature_prior_ratios, metrics_by_features = post_process_selected_features(\n",
    "    metadata_distributions=metadata_distributions,\n",
    "    class_distribution=class_distribution,\n",
    "    raw_predictions=preds_raw,\n",
    "    ground_truth_labels=GT_lbls\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97662dea-8eb6-4bd2-8372-d247ecdbcf5a",
   "metadata": {},
   "source": [
    "## Weighting by Combinations of Selected Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71b7a56-6592-49e1-8b3b-9a0fa61e4afd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "from postprocessing import weight_predictions_combined_feature_priors\n",
    "\n",
    "\n",
    "def post_process_prior_combinations(raw_predictions, feature_prior_ratios):\n",
    "    metrics_by_combination = {}\n",
    "    all_combinations_selected_features = []\n",
    "    for num_features in range(2, len(SELECTED_FEATURES) + 1):\n",
    "        all_combinations_selected_features.extend(combinations(SELECTED_FEATURES, num_features))\n",
    "    \n",
    "    for combination in all_combinations_selected_features:\n",
    "\n",
    "        selected_feature_prior_ratios = [feature_prior_ratios[feature] for feature in combination]\n",
    "\n",
    "        merged_predictions, merged_predictions_raw = weight_predictions_combined_feature_priors(\n",
    "            raw_predictions=raw_predictions,\n",
    "            feature_prior_ratios=selected_feature_prior_ratios\n",
    "        )\n",
    "\n",
    "        f1 = f1_score(test_df[TARGET_FEATURE], merged_predictions, average='macro')\n",
    "        accuracy = accuracy_score(test_df[TARGET_FEATURE], merged_predictions)\n",
    "        recall_3 = top_k_accuracy_score(test_df[TARGET_FEATURE], merged_predictions_raw, k=3)\n",
    "        \n",
    "        combination_name = \" + \".join(combination)\n",
    "        \n",
    "        metrics_by_combination[combination_name] = {\n",
    "            \"f1\": f1,\n",
    "            \"accuracy\": accuracy,\n",
    "            \"recall_3\": recall_3\n",
    "        }\n",
    "        print(combination_name)\n",
    "        print(\"F1, Acc, Recall3: \", f1, accuracy, recall_3)\n",
    "        print(\"Diff: \", np.around(f1-vanilla_f1, 3), np.around((accuracy-vanilla_accuracy) * 100, 2), np.around((recall_3-vanilla_recall_3)*100, 2))\n",
    "    \n",
    "    return metrics_by_combination\n",
    "        \n",
    "metrics_by_combination = post_process_prior_combinations(\n",
    "    raw_predictions=preds_raw,\n",
    "    feature_prior_ratios=feature_prior_ratios\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd261d5-1757-4b56-ab7c-787058e719f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = {\n",
    "    \"Vanilla\":       {'f1': vanilla_f1, 'accuracy': vanilla_accuracy, 'recall_3': vanilla_recall_3},\n",
    "    \"ObservationID\": {'f1': obs_f1, 'accuracy': obs_accuracy, 'recall_3': obs_recall_3}\n",
    "}\n",
    "results.update(metrics_by_features)\n",
    "results.update(metrics_by_combination)\n",
    "\n",
    "results_df = pd.DataFrame(results).transpose()\n",
    "results_df = results_df[['accuracy', 'recall_3', 'f1']]\n",
    "results_df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def subtract_base_performance(base: dict, post_processed: dict) -> dict:\n",
    "    difference = {}\n",
    "    for key, val in base.items():\n",
    "        difference[key] = post_processed[key] - val\n",
    "    return difference\n",
    "\n",
    "for key, val in results.items():\n",
    "    if key == \"Vanilla\":\n",
    "        continue\n",
    "    results[key] = subtract_base_performance(results[\"Vanilla\"], val)\n",
    "\n",
    "results_df = pd.DataFrame(results).transpose()\n",
    "results_df *= 100\n",
    "\n",
    "results_df = results_df.round(decimals=2)\n",
    "results_df = results_df[['accuracy', 'recall_3', 'f1']]\n",
    "results_df.head(50)\n",
    "result_message = f\"{results_df.to_markdown()}\\n\"\n",
    "print(result_message)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "be780d2ac419f0eb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from postprocessing import post_processing_pipeline\n",
    "\n",
    "\n",
    "post_processing_pipeline(\n",
    "    metadata,\n",
    "    model,\n",
    "    test_loader,\n",
    "    device,\n",
    "    TARGET_FEATURE,\n",
    "    SELECTED_FEATURES\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d97d8ffe7f33cdac"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
