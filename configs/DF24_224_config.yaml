# data
augmentations: 'vit_heavy'
image_size: [224, 224]
dataset: 'DF24'

# model
architecture: 'vit_base_patch16_224'

# training
train:
loss: 'CrossEntropyLoss'
optimizer: 'SGD'
scheduler: 'plateau'
epochs: 100
learning_rate: 0.01
batch_size: 64
accumulation_steps: 1

# other
random_seed: 777
workers: 8
multigpu: False
tags: ["DanishFungi2024", "224x224", "Transformer"]  # W&B Run tags
root_path: "../"